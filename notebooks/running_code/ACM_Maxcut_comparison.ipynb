{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9Pp-0W3dK9B",
        "outputId": "2dc47395-b755-4778-89fb-cea72afe48bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM3uxxzvexqU",
        "outputId": "1dbc6a6d-aa21-4209-c2b7-02aed0a80f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/TRVQA\n",
            "bench_10S_10I\t\t       bench_out_pl\n",
            "bench_10S_10I_start\t       bench_out_shot_diff\n",
            "benchmark\t\t       bench_out_shot_diff_2436\n",
            "bench_out\t\t       bench_out_shot_diff_24_real\n",
            "bench_out_100\t\t       bench_out_shot_diff_36_real\n",
            "bench_out_1000\t\t       bench_out_shot_diff_4816_real\n",
            "bench_out_100_old\t       bench_out_shot_diff_52\n",
            "bench_out_150\t\t       bench_out_shot_diff_52_real\n",
            "bench_out_2436\t\t       bench_tsp_4816\n",
            "bench_out_4816\t\t       bench_tsp_49\n",
            "bench_out_4816_lr_3\t       circuit.py\n",
            "bench_out_4816_old\t       ex_value_pots\n",
            "bench_out_4816_sv_compare      gates\n",
            "bench_out_52\t\t       hamiltonian\n",
            "bench_out_52_lr\t\t       __init__.py\n",
            "bench_out_52_memory\t       maxcut_comparison_CPU\n",
            "bench_out_52_old\t       maxcut_comparison_GPU\n",
            "bench_out_52_opt\t       measure\n",
            "bench_out_comparison\t       optimization\n",
            "bench_out_comparison_cpu_real  __pycache__\n",
            "bench_out_comparison_gpu       utils\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My\\ Drive/TRVQA\n",
        "\n",
        "# List files to make sure we're in the expected directory.\n",
        "# Your output will look different, showing your own Drive files here.\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FwsJJrPe0Nl",
        "outputId": "b74ce8e4-44a7-4849-de95-b8e3a6dba36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-691171030.py:2: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  sys.path.append('/content/drive/My\\ Drive/TRVQA')\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My\\ Drive/TRVQA')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12EnJMoVhCZT",
        "outputId": "91359984-c203-44fc-d2f8-d8836fbf8561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.2.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.2)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.5.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Downloading qiskit-2.2.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stevedore, rustworkx, qiskit\n",
            "Successfully installed qiskit-2.2.2 rustworkx-0.17.1 stevedore-5.5.0\n",
            "Collecting gurobipy\n",
            "  Downloading gurobipy-12.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (16 kB)\n",
            "Downloading gurobipy-12.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (14.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m149.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gurobipy\n",
            "Successfully installed gurobipy-12.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit\n",
        "!pip install gurobipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opEGTeSufEGV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import sys\n",
        "import os\n",
        "# Add the parent directory of TRVQA to sys.path\n",
        "from measure.enums import MeasureMethod\n",
        "from optimization.gradients.vanilla_parameter_shift import vanilla_parameter_shift\n",
        "from optimization.optimization import minimize, minimize_custom\n",
        "#from utils.maxcut import gengraph, create_hamiltonian, make_hamiltonian\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from qiskit.circuit.library import QAOAAnsatz\n",
        "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from circuit import Circuit\n",
        "\n",
        "def compute_maxcut_value(bitstring, graph):\n",
        "    \"\"\"Computes the MaxCut value for a given bitstring solution.\"\"\"\n",
        "    cut_value = sum(w for (u,v), w in graph if bitstring[u] != bitstring[v])\n",
        "    return cut_value\n",
        "\n",
        "# for s in best_value:\n",
        "#     print(compute_maxcut_value(s, g))\n",
        "\n",
        "from pyparsing import Optional\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp\n",
        "from optimization.optimization import minimize, minimize_custom\n",
        "# TRVQA imports\n",
        "\n",
        "from circuit import Circuit\n",
        "from hamiltonian.hamiltonian import Hamiltonian\n",
        "from measure.enums import MeasureMethod\n",
        "torch.cuda.empty_cache()\n",
        "import numpy as np\n",
        "import torch\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp\n",
        "import torch\n",
        "\n",
        "from measure.enums import MeasureMethod\n",
        "from optimization.optimization import minimize\n",
        "from utils.maxcut import gengraph, create_hamiltonian,make_hamiltonian\n",
        "from hamiltonian.hamiltonian import Hamiltonian\n",
        "import numpy as np\n",
        "import torch\n",
        "from circuit import Circuit\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guYTpZ7Ghxrt"
      },
      "outputs": [],
      "source": [
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import networkx as nx\n",
        "\n",
        "def maxcut_value(G) -> float:\n",
        "    \"\"\"\n",
        "    Solve weighted Max-Cut on an undirected NetworkX graph using Gurobi.\n",
        "\n",
        "    Args:\n",
        "        G: networkx.Graph\n",
        "           Undirected graph. Edge weights read from attribute 'weight' (default 1.0).\n",
        "\n",
        "    Returns:\n",
        "        float: Optimal Max-Cut value.\n",
        "    \"\"\"\n",
        "    # if not isinstance(G, nx.Graph) or G.is_directed():\n",
        "    #     raise ValueError(\"G must be an undirected networkx.Graph\")\n",
        "\n",
        "    model = gp.Model(\"MaxCut\")\n",
        "    model.Params.OutputFlag = 0  # silence solver output\n",
        "\n",
        "    # Binary variable x[i] ∈ {0,1} indicates partition side of node i\n",
        "    #nodes = list(G.nodes())\n",
        "    # Number of nodes\n",
        "    nodes = set()\n",
        "    for e,w in G:\n",
        "        u,v = e\n",
        "        nodes.add(u)\n",
        "        nodes.add(v)\n",
        "    n = len(nodes)\n",
        "\n",
        "    x = model.addVars(nodes, vtype=GRB.BINARY, name=\"x\")\n",
        "    # Objective: Maximize the cut value\n",
        "    model.setObjective(\n",
        "        gp.quicksum(w * (x[u] + x[v] - 2 * x[u] * x[v]) for (u, v), w in G),\n",
        "        GRB.MAXIMIZE\n",
        "    )\n",
        "\n",
        "    # Optimize the model\n",
        "    model.optimize()\n",
        "\n",
        "\n",
        "    if model.Status != GRB.OPTIMAL:\n",
        "        raise RuntimeError(f\"Gurobi did not find an optimal solution (status={model.Status}).\")\n",
        "\n",
        "    return float(model.ObjVal)\n",
        "import json\n",
        "\n",
        "N_list = [4, 8, 16, 24, 36, 52, 70, 90, 100]\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Dict, List, Tuple, Callable, Any\n",
        "import torch, numpy as np\n",
        "\n",
        "# --- Result container ---------------------------------------------------------\n",
        "@dataclass\n",
        "class RunLog:\n",
        "    exp_values: List[float]\n",
        "    best_results: List[Any]   # bitstrings, ints, etc.\n",
        "    iter_times: List[float]\n",
        "    final_theta: torch.Tensor\n",
        "\n",
        "# --- Helpers ------------------------------------------------------------------\n",
        "def build_qiskit_like_hamiltonian(hm):\n",
        "    \"\"\"hm is your [(coeff, bool_list), ...]\"\"\"\n",
        "    pauli_strings, coefficients = [], []\n",
        "    for coeff, bool_list in hm:\n",
        "        pauli_strings.append(''.join('Z' if b else 'I' for b in bool_list))\n",
        "        coefficients.append(coeff)\n",
        "    return Hamiltonian(len(bool_list), pauli_strings, coefficients)\n",
        "\n",
        "def build_circuit(N: int, D: int, rank: int = 10, device: str = 'cpu', isRing: bool = True) -> Circuit:\n",
        "    c = Circuit(N, device=device)\n",
        "    for _ in range(D):\n",
        "        for j in range(N): c.rx(j)\n",
        "        for j in range(N): c.rz(j)\n",
        "        for j in range(N-1): c.cx(j, j+1)\n",
        "        if isRing:\n",
        "            c.cx(N-1, 0)\n",
        "    c.rank = rank\n",
        "    return c\n",
        "\n",
        "# --- Method runners -----------------------------------------------------------\n",
        "def run_statevector_vqe(N: int, D: int, h, iter_steps: int, lr: float = 1e-2, theta0=None, isRing=True) -> RunLog:\n",
        "    model = QuantumCircuitTorch(theta0, N, D, h, isRing=isRing)\n",
        "    #opt = torch.optim.RMSprop(model.parameters(), lr =0.05, alpha=0.95, eps=1e-8, weight_decay=0.0)\n",
        "    opt = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "    exp_vals, best_results, iter_times = [], [], []\n",
        "    for _ in range(iter_steps):\n",
        "        start = time.time()\n",
        "        opt.zero_grad()\n",
        "        out = model()                   # expectation value (loss)\n",
        "        out.backward()\n",
        "        opt.step()\n",
        "        iter_times.append(time.time() - start)\n",
        "        exp_vals.append(float(out.item()))\n",
        "        best_results.append(get_opt_cut_sv(model.theta, N, D, h, isRing))\n",
        "        # if you track iteration time, append here (e.g., time.perf_counter deltas)\n",
        "    return RunLog(exp_values=exp_vals, best_results=best_results, iter_times=iter_times, final_theta=model.theta.detach().clone())\n",
        "\n",
        "def run_tr_vqe(method, circuit, theta0, hamil, iter_steps: int, lr: float, grad_kwargs: dict) -> RunLog:\n",
        "    \"\"\"Generic TR-VQE using your Optimizer + ParameterShift flavors.\"\"\"\n",
        "    # # Build gradient object with provided kwargs, override measure method:\n",
        "    from optimization.gradients.batch_parameter_shift import BatchParameterShiftGradient\n",
        "    from optimization.optimizer import Optimizer\n",
        "    grad = BatchParameterShiftGradient(\n",
        "        torch.pi/2,\n",
        "        grad_kwargs.get(\"batches\", 100),\n",
        "        grad_kwargs.get(\"shots\", int(1e3)),\n",
        "        method,                      # MeasureMethod\n",
        "        grad_kwargs.get(\"D\", 1)\n",
        "    )\n",
        "    opt = Optimizer(torch.optim.SGD, {'lr': 0.05})\n",
        "    #opt = Optimizer(torch.optim.AdamW, {'lr': lr})\n",
        "    #opt = Optimizer(torch.optim.AdamW, {'lr': lr})\n",
        "    # opt = Optimizer(torch.optim.RMSprop, {\n",
        "    #     \"lr\": 0.05,      # 0.03–0.04 works best at N=8\n",
        "    #     \"alpha\": 0.95,     # smoother EWMA than 0.9\n",
        "    #     \"eps\": 1e-8,\n",
        "    #     # \"momentum\": 0.9,   # NEW\n",
        "    #     # \"centered\": True,  # NEW\n",
        "    #     \"weight_decay\": 0.0,\n",
        "    # })\n",
        "    theta_init = theta0.clone().detach().requires_grad_(True)\n",
        "\n",
        "    new_theta, exp_vals, best_results, iter_times = minimize(\n",
        "        circuit, theta_init, hamil, opt, grad, iter_steps, best_value_method=\"argmax_tr_noinv_LE\"\n",
        "    )\n",
        "    return RunLog(\n",
        "        exp_values=[float(v.real) for v in exp_vals],\n",
        "        best_results=list(best_results),\n",
        "        iter_times=list(iter_times),\n",
        "        final_theta=new_theta.detach().clone()\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRboB40uKASO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Function\n",
        "from qiskit.circuit.library import QAOAAnsatz\n",
        "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "def run_circuit_sv(theta,N,D,h, isRing):\n",
        "    c = QuantumCircuit(N)\n",
        "    theta_t = 0\n",
        "    for i in range(D):\n",
        "        for ind1 in range(N):\n",
        "            c.rx(theta[theta_t].detach().cpu().item(), ind1)\n",
        "            theta_t+=1\n",
        "        for ind1 in range(N):\n",
        "            c.rz(theta[theta_t].detach().cpu().item(), ind1)\n",
        "            theta_t+=1\n",
        "        for ind1 in range(N-1):\n",
        "            c.cx(ind1, ind1+1)\n",
        "        if isRing:\n",
        "            c.cx(N-1,0)  # Add a CX to make it more complex\n",
        "    sv = Statevector(c).expectation_value(h)\n",
        "    return sv.real\n",
        "def get_opt_cut_sv(theta,N,D,h, isRing):\n",
        "    c = QuantumCircuit(N)\n",
        "    t = 0\n",
        "    for i in range(D):\n",
        "        for j in range(N):\n",
        "            c.rx(theta[t].detach().cpu().item(), j)\n",
        "            t+=1\n",
        "        for j in range(N):\n",
        "            c.rz(theta[t].detach().cpu().item(), j)\n",
        "            t+=1\n",
        "        for j in range(N-1):\n",
        "            c.cx(j, j+1)\n",
        "        if isRing:\n",
        "            c.cx(N-1,0)  # Add a CX to make it more complex\n",
        "    sv = Statevector(c)\n",
        "    my_dict = (sv.probabilities_dict())\n",
        "    max_key = min(my_dict, key=my_dict.get)\n",
        "    #print(\"min key\" , max_key)\n",
        "    probabilities = np.abs(sv) ** 2\n",
        "    # Step 2: Get index of highest probabili\n",
        "    max_index = probabilities.argmax()\n",
        "    return format(max_index,f'0{N}b')\n",
        "\n",
        "# Custom PyTorch autograd function\n",
        "class QuantumFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, theta, gates, N, h, D, isRing):\n",
        "        ctx.save_for_backward(theta)\n",
        "        ctx.gates = gates\n",
        "        ctx.N = N\n",
        "        ctx.D = D\n",
        "        ctx.h = h\n",
        "        ctx.isRing = isRing\n",
        "        output = run_circuit_sv(theta.detach(), N,D,h, isRing)\n",
        "        return torch.tensor([output], dtype=torch.float32)\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        theta, = ctx.saved_tensors\n",
        "        grad = parameter_shift_grad_sv(theta.detach(), ctx.gates, ctx.N, ctx.D, ctx.h, ctx.isRing)\n",
        "        return grad_output *grad, None, None, None, None, None\n",
        "# Parameter-shift gradient manually\n",
        "def parameter_shift_grad_sv(params, gates, N, D, h, isRing):\n",
        "    gradients = np.zeros_like(params)\n",
        "    shift = torch.tensor(torch.pi / 2)\n",
        "    for i in range(len(params)):\n",
        "        params_forward = params.clone()\n",
        "        params_backward = params.clone()\n",
        "        params_forward[i] += shift\n",
        "        params_backward[i] -= shift\n",
        "        gradients[i] = (run_circuit_sv(params_forward,N,D,h, isRing) - run_circuit_sv(params_backward, N,D,h, isRing)) / 2\n",
        "    return gradients\n",
        "\n",
        "# Wrap into a PyTorch module\n",
        "class QuantumCircuitTorch(torch.nn.Module):\n",
        "    def __init__(self, theta, N, D, h, isRing=True):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.D = D\n",
        "        self.h = h\n",
        "        self.gates = []\n",
        "        self.isRing = isRing\n",
        "        self.theta = torch.nn.Parameter(torch.tensor(theta, requires_grad=False))\n",
        "\n",
        "    def forward(self):\n",
        "        return QuantumFunction.apply(self.theta, self.gates, self.N, self.h, self.D, self.isRing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GzaIM1ncFWI"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Resume-in-place utilities\n",
        "# =========================\n",
        "import os, csv, json\n",
        "import torch\n",
        "\n",
        "def _read_summary(summary_csv=\"maxcut_comparison_CPU/summary.csv\"):\n",
        "    with open(summary_csv, \"r\") as f:\n",
        "        return list(csv.DictReader(f))\n",
        "\n",
        "def _write_summary_header_if_missing(summary_csv=\"maxcut_comparison_CPU/summary.csv\"):\n",
        "    if not os.path.exists(summary_csv):\n",
        "        with open(summary_csv, \"w\", newline=\"\") as f:\n",
        "            csv.writer(f).writerow([\"run_id\",\"method\",\"N\",\"depth\",\"seed\",\"theta_path\",\"iter_csv\"])\n",
        "\n",
        "def _find_run_row(method: str, N: int, D: int, seed: int, summary_csv=\"maxcut_comparison_CPU/summary.csv\"):\n",
        "    \"\"\"Return the LAST matching summary row (dict) or None.\"\"\"\n",
        "    if not os.path.exists(summary_csv):\n",
        "        return None\n",
        "    rows = _read_summary(summary_csv)\n",
        "    cand = [r for r in rows if r[\"method\"] == method and int(r[\"N\"]) == N and int(r[\"depth\"]) == D  and int(r[\"seed\"]) == seed]\n",
        "    return cand[-1] if cand else None\n",
        "\n",
        "def _read_last_iter(iter_csv_path: str) -> int:\n",
        "    \"\"\"Return last iteration index in iter CSV, or -1 if file empty.\"\"\"\n",
        "    if not os.path.exists(iter_csv_path):\n",
        "        return -1\n",
        "    last = -1\n",
        "    with open(iter_csv_path, \"r\") as f:\n",
        "        r = csv.DictReader(f)\n",
        "        for row in r:\n",
        "            last = int(row[\"iter\"])\n",
        "    return last\n",
        "\n",
        "def append_run_inplace(\n",
        "    runlog: RunLog,\n",
        "    *,\n",
        "    method: str,\n",
        "    N: int,\n",
        "    D: int,\n",
        "    seed: int,\n",
        "    outdir: str = \"maxcut_comparison_CPU\",\n",
        "    summary_csv: str = \"maxcut_comparison_CPU/summary.csv\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Append new iterations to the *existing* run for (method, N, seed),\n",
        "    and overwrite its final theta file. If not found, creates a new one.\n",
        "    Returns the run_id and paths.\n",
        "    \"\"\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    _write_summary_header_if_missing(summary_csv)\n",
        "\n",
        "    row = _find_run_row(method, N, D, seed, summary_csv)\n",
        "    if row is None:\n",
        "        # create a fresh entry (first time)\n",
        "        import uuid\n",
        "        run_id = str(uuid.uuid4())[:8]\n",
        "        theta_path = os.path.join(outdir, f\"theta_{run_id}.pt\")\n",
        "        iter_csv_path = os.path.join(outdir, f\"iter_{run_id}.csv\")\n",
        "        # write header for new iter file\n",
        "        with open(iter_csv_path, \"w\", newline=\"\") as f:\n",
        "            w = csv.writer(f); w.writerow([\"iter\",\"exp_value\",\"best_result\",\"iter_time\"])\n",
        "        # append summary row\n",
        "        with open(summary_csv, \"a\", newline=\"\") as f:\n",
        "            w = csv.writer(f)\n",
        "            w.writerow([run_id, method, N, D, seed, theta_path, iter_csv_path])\n",
        "    else:\n",
        "        run_id      = row[\"run_id\"]\n",
        "        theta_path  = row[\"theta_path\"]\n",
        "        iter_csv_path = row[\"iter_csv\"]\n",
        "\n",
        "    # figure out starting iteration index to continue\n",
        "    start_iter = _read_last_iter(iter_csv_path) + 1\n",
        "\n",
        "    # append new iteration rows with offset\n",
        "    with open(iter_csv_path, \"a\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        for i, (e, b, t) in enumerate(zip(runlog.exp_values, runlog.best_results, runlog.iter_times)):\n",
        "            w.writerow([start_iter + i, e, json.dumps(b), t])\n",
        "\n",
        "    # overwrite final theta\n",
        "    torch.save(runlog.final_theta.detach().cpu(), theta_path)\n",
        "\n",
        "    return {\"run_id\": run_id, \"theta_path\": theta_path, \"iter_csv\": iter_csv_path, \"start_iter\": start_iter}\n",
        "\n",
        "# =========================\n",
        "# Resume runner (in-place)\n",
        "# =========================\n",
        "def benchmark_resume_inplace(\n",
        "    method: str,\n",
        "    edges,\n",
        "    N: int,\n",
        "    D: int,\n",
        "    extra_iter_steps: int,\n",
        "    *,\n",
        "    seed: int,\n",
        "    theta_fallback: torch.Tensor,   # used only if no prior run exists\n",
        "    rank: int = 10,\n",
        "    isRing: bool = True,\n",
        "    lr_sv: float = 1e-2,\n",
        "    lr_tr: float = 1e-2,\n",
        "    shots: int | None = None,\n",
        "    batch_size_ef: int = 200,\n",
        "    batch_size_cs: int = 300,\n",
        "    batch_size_ps: int = 200,\n",
        "    outdir: str = \"maxcut_comparison_CPU\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Continue training the SAME run (method, N, seed). If not existing, starts fresh.\n",
        "    Appends new iterations to the existing CSV and overwrites final theta.\n",
        "    \"\"\"\n",
        "    # set seeds\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # try loading last theta (if run exists)\n",
        "    row = _find_run_row(method, N, D, seed, os.path.join(outdir, \"summary.csv\"))\n",
        "    if row is not None and os.path.exists(row[\"theta_path\"]):\n",
        "        theta0 = torch.load(row[\"theta_path\"], map_location=\"cpu\").detach()\n",
        "        print(f\"[resume] Loaded previous theta for ({method}, N={N}, seed={seed}).\")\n",
        "    else:\n",
        "        theta0 = theta_fallback.clone().detach()\n",
        "        print(f\"[resume] No previous run found; starting fresh for ({method}, N={N}, seed={seed}).\")\n",
        "\n",
        "    # build H and circuit (your helpers)\n",
        "    hm   = create_hamiltonian(N, edges)\n",
        "    h_qsv = make_hamiltonian(hm)\n",
        "    h_tr  = build_qiskit_like_hamiltonian(hm)\n",
        "    circuit = build_circuit(N, D, rank=rank, device=\"cpu\", isRing=isRing)\n",
        "\n",
        "    mm = {\n",
        "        \"tr_efficient\": MeasureMethod.EFFICIENT_CONTRACTION,\n",
        "        \"tr_correct_sampling\": MeasureMethod.CORRECT_SAMPLING,\n",
        "        \"tr_sampling\": MeasureMethod.SAMPLING,\n",
        "        \"sv\": \"SV\"\n",
        "    }[method]\n",
        "    if mm == MeasureMethod.CORRECT_SAMPLING:\n",
        "      grad_common = dict(batches=batch_size_cs, shots=(shots or 10_000), D=D, isRing=isRing)\n",
        "      runner = lambda: run_tr_vqe(mm, circuit, theta0, h_tr, extra_iter_steps, lr_tr, grad_common)\n",
        "    elif mm == MeasureMethod.SAMPLING:\n",
        "      grad_common = dict(batches=batch_size_ps, shots=(shots or 10_000), D=D, isRing=isRing)\n",
        "      runner = lambda: run_tr_vqe(mm, circuit, theta0, h_tr, extra_iter_steps, lr_tr, grad_common)\n",
        "    elif mm == \"SV\":\n",
        "      ## def run_statevector_vqe(N: int, D: int, h, iter_steps: int, lr: float = 1e-2, theta0=None, isRing=True) -> RunLog:\n",
        "      grad_common = dict(batches=100, shots=None, D=D, isRing=isRing)\n",
        "      runner = lambda: run_statevector_vqe(N, D, h_qsv, extra_iter_steps, lr=lr_tr, theta0=theta0, isRing=isRing)\n",
        "    else:\n",
        "      grad_common = dict(batches=batch_size_ef, shots=(shots or 10_000), D=D, isRing=isRing)\n",
        "      runner = lambda: run_tr_vqe(mm, circuit, theta0, h_tr, extra_iter_steps, lr_tr, grad_common)\n",
        "\n",
        "    # run extra steps\n",
        "    log: RunLog = runner()\n",
        "    # append-in-place + overwrite theta\n",
        "    info = append_run_inplace(log, method=method, N=N, D=D, seed=seed, outdir=outdir)\n",
        "    print(f\"[resume] Appended {len(log.exp_values)} iters starting from {info['start_iter']}.\")\n",
        "    return info, log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS7Q9Xo4gvp2"
      },
      "outputs": [],
      "source": [
        "# Load initial parameters\n",
        "theta_init_by_seed = []\n",
        "for i in range(10):\n",
        "  a = torch.load(f\"/content/drive/MyDrive/TRVQA/benchmark/theta_inits/theta_init_s{i}.pt\")\n",
        "  b = torch.load(f\"/content/drive/MyDrive/TRVQA/benchmark/theta_inits/theta_init_s{i}_extra.pt\")\n",
        "  theta_init_by_seed.append(torch.cat([a,b]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdEI2OeEWQK4"
      },
      "outputs": [],
      "source": [
        "with open(\"benchmark/experiment_grid.json\", \"r\") as f:\n",
        "    loaded = json.load(f)\n",
        "\n",
        "# Convert lists back to tuples if you want\n",
        "def convert_lists_to_tuples(obj):\n",
        "    if isinstance(obj, list):\n",
        "        # Check if list looks like an edge [(0,1), w]\n",
        "        if len(obj) == 2 and isinstance(obj[0], list) and isinstance(obj[1], (int, float)):\n",
        "            return (tuple(obj[0]), obj[1])\n",
        "        else:\n",
        "            return [convert_lists_to_tuples(x) for x in obj]\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: convert_lists_to_tuples(v) for k, v in obj.items()}\n",
        "    return obj\n",
        "\n",
        "graph_by_seed = [convert_lists_to_tuples(entry) for entry in loaded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4mDv5acBp8j",
        "outputId": "162afa17-801f-430f-da08-34eb264b7912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 8, 16, 24, 36, 52, 70, 90, 100]\n"
          ]
        }
      ],
      "source": [
        "print(N_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Soxbj4cICo",
        "outputId": "c34dac0c-b051-4f9e-9eda-ad57137a58bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Graph 0] depth=3, seed=0, N=4\n",
            "[resume] Loaded previous theta for (tr_efficient, N=4, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:00 | Loss: 12.2527[resume] Appended 10 iters starting from 10.\n",
            "updated files: {'run_id': '5c878e8f', 'theta_path': 'maxcut_comparison_CPU/theta_5c878e8f.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_5c878e8f.csv', 'start_iter': 10}\n",
            "[Graph 0] depth=3, seed=0, N=4\n",
            "[resume] Loaded previous theta for (tr_correct_sampling, N=4, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:00 | Loss: 11.6878[resume] Appended 10 iters starting from 10.\n",
            "updated files: {'run_id': '9520ff0a', 'theta_path': 'maxcut_comparison_CPU/theta_9520ff0a.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_9520ff0a.csv', 'start_iter': 10}\n",
            "[Graph 0] depth=3, seed=0, N=4\n",
            "[resume] No previous run found; starting fresh for (tr_sampling, N=4, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:00 | Loss: 16.9254+0.0000j[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '71fb6b5e', 'theta_path': 'maxcut_comparison_CPU/theta_71fb6b5e.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_71fb6b5e.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=8\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=8, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:00 | Loss: 25.2834[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '48cac952', 'theta_path': 'maxcut_comparison_CPU/theta_48cac952.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_48cac952.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=8\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=8, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:02 | Loss: 25.3945[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '3dabec4f', 'theta_path': 'maxcut_comparison_CPU/theta_3dabec4f.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_3dabec4f.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=8\n",
            "[resume] No previous run found; starting fresh for (tr_sampling, N=8, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:01 | Loss: 27.0253+0.0000j[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '3591d8fc', 'theta_path': 'maxcut_comparison_CPU/theta_3591d8fc.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_3591d8fc.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=16\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=16, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:04 | Loss: 72.2795[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': 'fc4a0f8d', 'theta_path': 'maxcut_comparison_CPU/theta_fc4a0f8d.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_fc4a0f8d.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=16\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=16, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:07 | Loss: 71.8081[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '0cff6063', 'theta_path': 'maxcut_comparison_CPU/theta_0cff6063.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_0cff6063.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=16\n",
            "[resume] No previous run found; starting fresh for (tr_sampling, N=16, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:06 | Loss: 72.6021+0.0000j[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': 'b4245d05', 'theta_path': 'maxcut_comparison_CPU/theta_b4245d05.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_b4245d05.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=24\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=24, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:13 | Loss: 106.9129[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '128aa640', 'theta_path': 'maxcut_comparison_CPU/theta_128aa640.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_128aa640.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=24\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=24, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:16 | Loss: 106.4300[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '199ddae1', 'theta_path': 'maxcut_comparison_CPU/theta_199ddae1.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_199ddae1.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=24\n",
            "[resume] No previous run found; starting fresh for (tr_sampling, N=24, seed=0).\n",
            "Progress: [==========================>   ] 90% | ETA: 00:13 | Loss: 108.2765+0.0000j[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '3b76f60b', 'theta_path': 'maxcut_comparison_CPU/theta_3b76f60b.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_3b76f60b.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=4\n",
            "[resume] No previous run found; starting fresh for (sv, N=4, seed=0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3869030728.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.theta = torch.nn.Parameter(torch.tensor(theta, requires_grad=False))\n",
            "/tmp/ipython-input-3869030728.py:62: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  return grad_output *grad, None, None, None, None, None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '57e098ad', 'theta_path': 'maxcut_comparison_CPU/theta_57e098ad.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_57e098ad.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=8\n",
            "[resume] No previous run found; starting fresh for (sv, N=8, seed=0).\n",
            "[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '152caf8f', 'theta_path': 'maxcut_comparison_CPU/theta_152caf8f.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_152caf8f.csv', 'start_iter': 0}\n",
            "[Graph 0] depth=3, seed=0, N=16\n",
            "[resume] No previous run found; starting fresh for (sv, N=16, seed=0).\n",
            "[resume] Appended 10 iters starting from 0.\n",
            "updated files: {'run_id': '4c7240c7', 'theta_path': 'maxcut_comparison_CPU/theta_4c7240c7.pt', 'iter_csv': 'maxcut_comparison_CPU/iter_4c7240c7.csv', 'start_iter': 0}\n"
          ]
        }
      ],
      "source": [
        "# Example: running over D and seeds for one specific graph_id and N\n",
        "# target_graph_id = 2  # or loop over several ids\n",
        "graph_lookup = {(g['N'], g['graph_id']): g['G'] for g in graph_by_seed}\n",
        "# assert N == target_N  # optional sanity check\n",
        "for N in [4,8,16,24]:\n",
        "  for D in [3]:\n",
        "      for seed in [0]:\n",
        "          target_N = N\n",
        "          g = graph_lookup[(target_N, seed)]\n",
        "          N = max(max(u, v) for (u, v), _ in g) + 1  # or just use target_N\n",
        "          param_size = 2 * D * N\n",
        "          theta0 = theta_init_by_seed[seed][:param_size]\n",
        "          for meth in [\"tr_efficient\", \"tr_correct_sampling\", \"tr_sampling\"]:\n",
        "              print(f\"[Graph {seed}] depth={D}, seed={seed}, N={N}\")\n",
        "\n",
        "              info, log = benchmark_resume_inplace(\n",
        "                  method=meth,\n",
        "                  edges=g,\n",
        "                  N=N,\n",
        "                  D=D,\n",
        "                  extra_iter_steps=10,\n",
        "                  seed=seed,\n",
        "                  theta_fallback=theta0,\n",
        "                  rank=10,\n",
        "                  isRing=True,\n",
        "                  lr_tr=1e-2,\n",
        "                  shots=int(1e3),\n",
        "                  outdir=\"maxcut_comparison_CPU\",\n",
        "                  batch_size_ef=400,\n",
        "                  batch_size_cs=600,\n",
        "                  batch_size_ps=1000,\n",
        "              )\n",
        "\n",
        "              torch.cuda.empty_cache()\n",
        "              print(\"updated files:\", info)\n",
        "for N in [4,8,16]:\n",
        "  for D in [3]:\n",
        "      for seed in [0]:\n",
        "          target_N = N\n",
        "          g = graph_lookup[(target_N, seed)]\n",
        "          N = max(max(u, v) for (u, v), _ in g) + 1  # or just use target_N\n",
        "          param_size = 2 * D * N\n",
        "          theta0 = theta_init_by_seed[seed][:param_size]\n",
        "          for meth in [\"sv\"]:\n",
        "              print(f\"[Graph {seed}] depth={D}, seed={seed}, N={N}\")\n",
        "\n",
        "              info, log = benchmark_resume_inplace(\n",
        "                  method=meth,\n",
        "                  edges=g,\n",
        "                  N=N,\n",
        "                  D=D,\n",
        "                  extra_iter_steps=10,\n",
        "                  seed=seed,\n",
        "                  theta_fallback=theta0,\n",
        "                  rank=10,\n",
        "                  isRing=True,\n",
        "                  lr_tr=1e-2,\n",
        "                  shots=int(1e3),\n",
        "                  outdir=\"maxcut_comparison_CPU\",\n",
        "                  batch_size_ef=400,\n",
        "                  batch_size_cs=600,\n",
        "                  batch_size_ps=1000,\n",
        "              )\n",
        "\n",
        "              torch.cuda.empty_cache()\n",
        "              print(\"updated files:\", info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvOsolghyhUX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "outputId": "1298fa03-3393-46af-a87f-7e923bb1b7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Ipython in /usr/local/lib/python3.12/dist-packages (7.34.0)\n",
            "Collecting Ipython\n",
            "  Downloading ipython-9.6.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from Ipython) (4.4.2)\n",
            "Collecting ipython-pygments-lexers (from Ipython)\n",
            "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jedi>=0.16 (from Ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from Ipython) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from Ipython) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from Ipython) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from Ipython) (2.19.2)\n",
            "Collecting stack_data (from Ipython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.13.0 (from Ipython)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->Ipython) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->Ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->Ipython) (0.2.14)\n",
            "Collecting executing>=1.2.0 (from stack_data->Ipython)\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->Ipython)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->Ipython)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading ipython-9.6.0-py3-none-any.whl (616 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.2/616.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pure-eval, traitlets, jedi, ipython-pygments-lexers, executing, asttokens, stack_data, Ipython\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: Ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 9.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Ipython-9.6.0 asttokens-3.0.0 executing-2.2.1 ipython-pygments-lexers-1.1.1 jedi-0.19.2 pure-eval-0.2.3 stack_data-0.6.3 traitlets-5.14.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "traitlets"
                ]
              },
              "id": "a5ac6e25d9094c758f5185777c3b0f2c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install Ipython --upgrade\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP1jdXW4hZK5"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optimization.optimization import minimize"
      ],
      "metadata": {
        "id": "jPoc_F5BsMAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RpEwnLjjsk_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U9XJIQlXsdE7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}