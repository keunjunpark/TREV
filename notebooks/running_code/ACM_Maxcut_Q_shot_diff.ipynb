{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9Pp-0W3dK9B",
        "outputId": "89037abf-7f56-489b-9382-c1afb54c79e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM3uxxzvexqU",
        "outputId": "5d747a4f-f3ad-41de-87dd-0f3991f39de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/TRVQA\n",
            "benchmark\t\t       circuit.py     __init__.py   utils\n",
            "bench_tsp_shot_diff_25_real    ex_value_pots  measure\n",
            "bench_tsp_shot_diff_4816_real  gates\t      optimization\n",
            "bench_tsp_shot_diff_49_real    hamiltonian    __pycache__\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My\\ Drive/TRVQA\n",
        "\n",
        "# List files to make sure we're in the expected directory.\n",
        "# Your output will look different, showing your own Drive files here.\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FwsJJrPe0Nl",
        "outputId": "51f0bcfa-647e-4139-c58c-d57fddfa4713"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-691171030.py:2: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  sys.path.append('/content/drive/My\\ Drive/TRVQA')\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My\\ Drive/TRVQA')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12EnJMoVhCZT",
        "outputId": "e7e16e6e-fb79-42b5-d375-c2e165ed43b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.2.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.2)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.5.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Downloading qiskit-2.2.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stevedore, rustworkx, qiskit\n",
            "Successfully installed qiskit-2.2.2 rustworkx-0.17.1 stevedore-5.5.0\n",
            "Collecting gurobipy\n",
            "  Downloading gurobipy-12.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (16 kB)\n",
            "Downloading gurobipy-12.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (14.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gurobipy\n",
            "Successfully installed gurobipy-12.0.3\n",
            "Collecting qiskit_optimization\n",
            "  Downloading qiskit_optimization-0.7.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: qiskit<3,>=1.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_optimization) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from qiskit_optimization) (1.16.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit_optimization) (2.0.2)\n",
            "Collecting docplex!=2.24.231,>=2.21.207 (from qiskit_optimization)\n",
            "  Downloading docplex-2.30.251.tar.gz (646 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m646.5/646.5 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.12/dist-packages (from qiskit_optimization) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.6.3 in /usr/local/lib/python3.12/dist-packages (from qiskit_optimization) (3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from docplex!=2.24.231,>=2.21.207->qiskit_optimization) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit<3,>=1.1->qiskit_optimization) (0.17.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit<3,>=1.1->qiskit_optimization) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit<3,>=1.1->qiskit_optimization) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit<3,>=1.1->qiskit_optimization) (4.15.0)\n",
            "Downloading qiskit_optimization-0.7.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.1/237.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docplex\n",
            "  Building wheel for docplex (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docplex: filename=docplex-2.30.251-py3-none-any.whl size=685954 sha256=f1132f5f39b9d58c0b6d7f62549f451e573512f6ca936807c01c8d19c21c0c4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/d9/5c/1d919b1e441ebbaff244513a13d09c3c0378401601d4184bb0\n",
            "Successfully built docplex\n",
            "Installing collected packages: docplex, qiskit_optimization\n",
            "Successfully installed docplex-2.30.251 qiskit_optimization-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit\n",
        "!pip install gurobipy\n",
        "!pip install qiskit_optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opEGTeSufEGV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import sys\n",
        "import os\n",
        "# Add the parent directory of TRVQA to sys.path\n",
        "from measure.enums import MeasureMethod\n",
        "from optimization.gradients.vanilla_parameter_shift import vanilla_parameter_shift\n",
        "from optimization.optimization import minimize, minimize_custom\n",
        "#from utils.maxcut import gengraph, create_hamiltonian, make_hamiltonian\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from qiskit.circuit.library import QAOAAnsatz\n",
        "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from circuit import Circuit\n",
        "\n",
        "def compute_maxcut_value(bitstring, graph):\n",
        "    \"\"\"Computes the MaxCut value for a given bitstring solution.\"\"\"\n",
        "    cut_value = sum(w for (u,v), w in graph if bitstring[u] != bitstring[v])\n",
        "    return cut_value\n",
        "\n",
        "# for s in best_value:\n",
        "#     print(compute_maxcut_value(s, g))\n",
        "\n",
        "from pyparsing import Optional\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp\n",
        "from optimization.optimization import minimize, minimize_custom\n",
        "# TRVQA imports\n",
        "\n",
        "from circuit import Circuit\n",
        "from hamiltonian.hamiltonian import Hamiltonian\n",
        "from measure.enums import MeasureMethod\n",
        "torch.cuda.empty_cache()\n",
        "import numpy as np\n",
        "import torch\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp\n",
        "import torch\n",
        "\n",
        "from measure.enums import MeasureMethod\n",
        "from optimization.optimization import minimize\n",
        "from utils.maxcut import gengraph, create_hamiltonian,make_hamiltonian\n",
        "from hamiltonian.hamiltonian import Hamiltonian\n",
        "import numpy as np\n",
        "import torch\n",
        "from circuit import Circuit\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guYTpZ7Ghxrt"
      },
      "outputs": [],
      "source": [
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import networkx as nx\n",
        "\n",
        "def maxcut_value(G) -> float:\n",
        "    \"\"\"\n",
        "    Solve weighted Max-Cut on an undirected NetworkX graph using Gurobi.\n",
        "\n",
        "    Args:\n",
        "        G: networkx.Graph\n",
        "           Undirected graph. Edge weights read from attribute 'weight' (default 1.0).\n",
        "\n",
        "    Returns:\n",
        "        float: Optimal Max-Cut value.\n",
        "    \"\"\"\n",
        "    # if not isinstance(G, nx.Graph) or G.is_directed():\n",
        "    #     raise ValueError(\"G must be an undirected networkx.Graph\")\n",
        "\n",
        "    model = gp.Model(\"MaxCut\")\n",
        "    model.Params.OutputFlag = 0  # silence solver output\n",
        "\n",
        "    # Binary variable x[i] ∈ {0,1} indicates partition side of node i\n",
        "    #nodes = list(G.nodes())\n",
        "    # Number of nodes\n",
        "    nodes = set()\n",
        "    for e,w in G:\n",
        "        u,v = e\n",
        "        nodes.add(u)\n",
        "        nodes.add(v)\n",
        "    n = len(nodes)\n",
        "\n",
        "    x = model.addVars(nodes, vtype=GRB.BINARY, name=\"x\")\n",
        "    # Objective: Maximize the cut value\n",
        "    model.setObjective(\n",
        "        gp.quicksum(w * (x[u] + x[v] - 2 * x[u] * x[v]) for (u, v), w in G),\n",
        "        GRB.MAXIMIZE\n",
        "    )\n",
        "\n",
        "    # Optimize the model\n",
        "    model.optimize()\n",
        "\n",
        "\n",
        "    if model.Status != GRB.OPTIMAL:\n",
        "        raise RuntimeError(f\"Gurobi did not find an optimal solution (status={model.Status}).\")\n",
        "\n",
        "    return float(model.ObjVal)\n",
        "import json\n",
        "\n",
        "N_list = [4, 8, 16, 24, 36, 52, 70, 90, 100]\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Dict, List, Tuple, Callable, Any\n",
        "import torch, numpy as np\n",
        "\n",
        "# --- Result container ---------------------------------------------------------\n",
        "@dataclass\n",
        "class RunLog:\n",
        "    exp_values: List[float]\n",
        "    best_results: List[Any]   # bitstrings, ints, etc.\n",
        "    iter_times: List[float]\n",
        "    final_theta: torch.Tensor\n",
        "\n",
        "# --- Helpers ------------------------------------------------------------------\n",
        "# --- Helpers ------------------------------------------------------------------\n",
        "def build_qiskit_like_hamiltonian(hm):\n",
        "    \"\"\"hm is your [(coeff, bool_list), ...]\"\"\"\n",
        "    pauli_strings, coefficients = [], []\n",
        "    for elm in hm:\n",
        "        coeff, pauli = elm.coeffs[0], elm.paulis[0]\n",
        "\n",
        "        pauli_strings.append(str(pauli[::-1]))\n",
        "        coefficients.append(float(coeff))\n",
        "    # print(pauli_strings)\n",
        "    # print(coefficients)\n",
        "    return Hamiltonian(len(pauli_strings[0]), pauli_strings, coefficients)\n",
        "def build_circuit(N: int, D: int, rank: int = 10, device: str = 'cuda', isRing: bool = True) -> Circuit:\n",
        "    c = Circuit(N, device=device)\n",
        "    for _ in range(D):\n",
        "        for j in range(N): c.rx(j)\n",
        "        for j in range(N): c.rz(j)\n",
        "        for j in range(N-1): c.cx(j, j+1)\n",
        "        if isRing:\n",
        "            c.cx(N-1, 0)\n",
        "    c.rank = rank\n",
        "    return c\n",
        "\n",
        "# --- Method runners -----------------------------------------------------------\n",
        "def run_statevector_vqe(N: int, D: int, h, iter_steps: int, lr: float = 1e-2, theta0=None, isRing=True) -> RunLog:\n",
        "    model = QuantumCircuitTorch(theta0, N, D, h, isRing=isRing)\n",
        "    opt = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    exp_vals, best_results, iter_times = [], [], []\n",
        "    for _ in range(iter_steps):\n",
        "        opt.zero_grad()\n",
        "        out = model()                   # expectation value (loss)\n",
        "        out.backward()\n",
        "        opt.step()\n",
        "        exp_vals.append(float(out.item()))\n",
        "        best_results.append(get_opt_cut_sv(model.theta, N, D, h, isRing))\n",
        "        # if you track iteration time, append here (e.g., time.perf_counter deltas)\n",
        "    return RunLog(exp_values=exp_vals, best_results=best_results, iter_times=iter_times, final_theta=model.theta.detach().clone())\n",
        "\n",
        "def run_tr_vqe(method, circuit, theta0, hamil, iter_steps: int, opt, grad_kwargs: dict) -> RunLog:\n",
        "    \"\"\"Generic TR-VQE using your Optimizer + ParameterShift flavors.\"\"\"\n",
        "    # # Build gradient object with provided kwargs, override measure method:\n",
        "    from optimization.gradients.batch_parameter_shift import BatchParameterShiftGradient\n",
        "    from optimization.optimizer import Optimizer\n",
        "    grad = BatchParameterShiftGradient(\n",
        "        torch.pi/2,\n",
        "        grad_kwargs.get(\"batches\", 100),\n",
        "        grad_kwargs.get(\"shots\", int(1e3)),\n",
        "        method,                      # MeasureMethod\n",
        "        grad_kwargs.get(\"D\", 1)\n",
        "    )\n",
        "    #opt = Optimizer(torch.optim.AdamW, {'lr': lr})\n",
        "    #opt = Optimizer(torch.optim.AdamW, {'lr': lr})\n",
        "    # opt = Optimizer(torch.optim.RMSprop, {\n",
        "    #     \"lr\": 0.05,      # 0.03–0.04 works best at N=8\n",
        "    #     \"alpha\": 0.95,     # smoother EWMA than 0.9\n",
        "    #     \"eps\": 1e-8,\n",
        "    #     # \"momentum\": 0.9,   # NEW\n",
        "    #     # \"centered\": True,  # NEW\n",
        "    #     \"weight_decay\": 0.0,\n",
        "    # })\n",
        "    theta_init = theta0.clone().detach().requires_grad_(True)\n",
        "\n",
        "    new_theta, exp_vals, best_results, iter_times = minimize(\n",
        "        circuit, theta_init, hamil, opt, grad, iter_steps, best_value_method=\"argmax_tr_noinv_LE\"\n",
        "    )\n",
        "    return RunLog(\n",
        "        exp_values=[float(v.real) for v in exp_vals],\n",
        "        best_results=list(best_results),\n",
        "        iter_times=list(iter_times),\n",
        "        final_theta=new_theta.detach().clone()\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GzaIM1ncFWI"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Resume-in-place utilities (with optimizer_name + optimizer object creation)\n",
        "# =========================\n",
        "import os, csv, json\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# ---------- Summary utilities ----------\n",
        "\n",
        "def _read_summary(summary_csv=\"bench_tsp_shot_diff_49_real/summary.csv\"):\n",
        "    with open(summary_csv, \"r\") as f:\n",
        "        return list(csv.DictReader(f))\n",
        "\n",
        "def _write_summary_header_if_missing(summary_csv=\"bench_tsp_shot_diff_49_real/summary.csv\"):\n",
        "    if not os.path.exists(summary_csv):\n",
        "        with open(summary_csv, \"w\", newline=\"\") as f:\n",
        "            csv.writer(f).writerow([\n",
        "                \"run_id\",\"method\",\"N\",\"depth\",\"seed\",\n",
        "                \"theta_path\",\"iter_csv\",\"optimizer_name\", \"shots\"   # ✅ optimizer column\n",
        "            ])\n",
        "\n",
        "def _find_run_row(\n",
        "    method: str,\n",
        "    N: int,\n",
        "    D: int,\n",
        "    seed: int,\n",
        "    optimizer_name: str | None = None,\n",
        "    shots = None,\n",
        "    summary_csv=\"bench_tsp_shot_diff_49_real/summary.csv\"\n",
        "):\n",
        "    \"\"\"Return the LAST matching summary row (dict) or None.\"\"\"\n",
        "    if not os.path.exists(summary_csv):\n",
        "        return None\n",
        "    rows = _read_summary(summary_csv)\n",
        "    cand = [\n",
        "        r for r in rows\n",
        "        if r[\"method\"] == method\n",
        "        and int(r[\"N\"]) == N\n",
        "        and int(r[\"depth\"]) == D\n",
        "        and int(r[\"seed\"]) == seed\n",
        "        and (optimizer_name is None or r.get(\"optimizer_name\", \"\") == optimizer_name)\n",
        "        and int(r['shots']) == shots\n",
        "    ]\n",
        "    return cand[-1] if cand else None\n",
        "\n",
        "def _read_last_iter(iter_csv_path: str) -> int:\n",
        "    \"\"\"Return last iteration index in iter CSV, or -1 if file empty.\"\"\"\n",
        "    if not os.path.exists(iter_csv_path):\n",
        "        return -1\n",
        "    last = -1\n",
        "    with open(iter_csv_path, \"r\") as f:\n",
        "        r = csv.DictReader(f)\n",
        "        for row in r:\n",
        "            last = int(row[\"iter\"])\n",
        "    return last\n",
        "\n",
        "# ---------- Append run ----------\n",
        "\n",
        "def append_run_inplace(\n",
        "    runlog: \"RunLog\",\n",
        "    *,\n",
        "    method: str,\n",
        "    N: int,\n",
        "    D: int,\n",
        "    seed: int,\n",
        "    optimizer_name: str = \"\",\n",
        "    outdir: str = \"bench_tsp_shot_diff_49_real\",\n",
        "    summary_csv: str = \"bench_tsp_shot_diff_49_real/summary.csv\",\n",
        "    shots = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Append new iterations to the *existing* run for (method, N, D, seed, optimizer_name),\n",
        "    and overwrite its final theta file. If not found, creates a new one.\n",
        "    \"\"\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    _write_summary_header_if_missing(summary_csv)\n",
        "\n",
        "    row = _find_run_row(method, N, D, seed, optimizer_name,shots, summary_csv)\n",
        "\n",
        "    if row is None:\n",
        "        import uuid\n",
        "        run_id = str(uuid.uuid4())[:8]\n",
        "        theta_path = os.path.join(outdir, f\"theta_{run_id}.pt\")\n",
        "        iter_csv_path = os.path.join(outdir, f\"iter_{run_id}.csv\")\n",
        "        with open(iter_csv_path, \"w\", newline=\"\") as f:\n",
        "            w = csv.writer(f); w.writerow([\"iter\",\"exp_value\",\"best_result\",\"iter_time\"])\n",
        "        with open(summary_csv, \"a\", newline=\"\") as f:\n",
        "            w = csv.writer(f)\n",
        "            w.writerow([run_id, method, N, D, seed, theta_path, iter_csv_path, optimizer_name, shots])\n",
        "    else:\n",
        "        run_id        = row[\"run_id\"]\n",
        "        theta_path    = row[\"theta_path\"]\n",
        "        iter_csv_path = row[\"iter_csv\"]\n",
        "        if optimizer_name and row.get(\"optimizer_name\", \"\") != optimizer_name:\n",
        "            rows = _read_summary(summary_csv)\n",
        "            for r in rows:\n",
        "                if r[\"run_id\"] == run_id:\n",
        "                    r[\"optimizer_name\"] = optimizer_name\n",
        "            with open(summary_csv, \"w\", newline=\"\") as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=rows[0].keys())\n",
        "                writer.writeheader()\n",
        "                writer.writerows(rows)\n",
        "\n",
        "    start_iter = _read_last_iter(iter_csv_path) + 1\n",
        "\n",
        "    with open(iter_csv_path, \"a\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        for i, (e, b, t) in enumerate(zip(runlog.exp_values, runlog.best_results, runlog.iter_times)):\n",
        "            w.writerow([start_iter + i, e, json.dumps(b), t])\n",
        "\n",
        "    torch.save(runlog.final_theta.detach().cpu(), theta_path)\n",
        "\n",
        "    return {\n",
        "        \"run_id\": run_id,\n",
        "        \"theta_path\": theta_path,\n",
        "        \"iter_csv\": iter_csv_path,\n",
        "        \"start_iter\": start_iter\n",
        "    }\n",
        "\n",
        "# ---------- Helper: create optimizer ----------\n",
        "\n",
        "def _make_optimizer(name: str, params, lr: float):\n",
        "    \"\"\"\n",
        "    Construct optimizer object from name string.\n",
        "    Extend here for more optimizers easily.\n",
        "    \"\"\"\n",
        "    name = name.lower()\n",
        "    if name == \"adam\":\n",
        "        return optim.Adam([params], lr=lr)\n",
        "    elif name == \"adamw\":\n",
        "        return optim.AdamW([params], lr=lr)\n",
        "    elif name == \"sgd\":\n",
        "        return optim.SGD([params], lr=lr, momentum=0.9)\n",
        "    elif name == \"rmsprop\":\n",
        "        return optim.RMSprop([params], lr=lr)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer: {name}\")\n",
        "\n",
        "# ---------- Resume runner ----------\n",
        "\n",
        "def benchmark_resume_inplace(\n",
        "    method: str,\n",
        "    edges,\n",
        "    N: int,\n",
        "    D: int,\n",
        "    extra_iter_steps: int,\n",
        "    *,\n",
        "    seed: int,\n",
        "    optimizer_name: str,\n",
        "    optimizer,\n",
        "    theta_fallback: torch.Tensor,   # used only if no prior run exists\n",
        "    lr: float = 1e-2,               # ✅ unified learning rate\n",
        "    rank: int = 10,\n",
        "    isRing: bool = True,\n",
        "    shots: int | None = None,\n",
        "    batch_size_ef: int = 200,\n",
        "    batch_size_cs: int = 300,\n",
        "    batch_size_ps: int = 200,\n",
        "    outdir: str = \"bench_tsp_shot_diff_49_real\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Continue training the SAME run (method, N, D, seed, optimizer_name).\n",
        "    Creates optimizer internally and passes it to the runner.\n",
        "    \"\"\"\n",
        "    # set seeds\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # try loading last theta (if run exists)\n",
        "    row = _find_run_row(method, N, D, seed, optimizer_name, shots, os.path.join(outdir, \"summary.csv\"))\n",
        "    if row is not None and os.path.exists(row[\"theta_path\"]):\n",
        "        theta0 = torch.load(row[\"theta_path\"], map_location=\"cpu\").detach()\n",
        "        print(f\"[resume] Loaded previous theta for ({method}, N={N}, seed={seed}, optimizer={optimizer_name}).\")\n",
        "    else:\n",
        "        theta0 = theta_fallback.clone().detach()\n",
        "        print(f\"[resume] No previous run found; starting fresh for ({method}, N={N}, seed={seed}, optimizer={optimizer_name}).\")\n",
        "    temp_tsp = Tsp(edges)\n",
        "    qp = temp_tsp.to_quadratic_program()\n",
        "    qp2qubo = QuadraticProgramToQubo()\n",
        "    qubo = qp2qubo.convert(qp)\n",
        "    qubitOp, offset = qubo.to_ising()\n",
        "    # build H and circuit (your helpers)\n",
        "    h_qsv = qubitOp\n",
        "    h_tr  = build_qiskit_like_hamiltonian(qubitOp)\n",
        "    circuit = build_circuit(N, D, rank=rank, device=\"cuda\", isRing=isRing)\n",
        "\n",
        "    # ✅ Create optimizer here\n",
        "    theta0 = theta0.clone().detach().requires_grad_(True)\n",
        "    #optimizer = _make_optimizer(optimizer_name, theta0, lr)\n",
        "\n",
        "    # select measurement method\n",
        "    mm = {\n",
        "        \"tr_efficient\": MeasureMethod.EFFICIENT_CONTRACTION,\n",
        "        \"tr_correct_sampling\": MeasureMethod.CORRECT_SAMPLING,\n",
        "        \"tr_sampling\": MeasureMethod.SAMPLING,\n",
        "    }[method]\n",
        "    if mm == MeasureMethod.CORRECT_SAMPLING:\n",
        "        grad_common = dict(batches=batch_size_cs, shots=(shots or 10_000), D=D, isRing=isRing)\n",
        "    elif mm == MeasureMethod.SAMPLING:\n",
        "        grad_common = dict(batches=batch_size_ps, shots=(shots or 10_000), D=D, isRing=isRing)\n",
        "    else:\n",
        "        grad_common = dict(batches=batch_size_ef, shots=(shots or 10_000), D=D, isRing=isRing)\n",
        "\n",
        "    # ✅ Pass optimizer into your training loop\n",
        "    runner = lambda: run_tr_vqe(\n",
        "        mm,\n",
        "        circuit,\n",
        "        theta0,\n",
        "        h_tr,\n",
        "        extra_iter_steps,\n",
        "        optimizer,\n",
        "        grad_common\n",
        "    )\n",
        "\n",
        "    # run extra steps\n",
        "    log: RunLog = runner()\n",
        "\n",
        "    # append-in-place + overwrite theta\n",
        "    info = append_run_inplace(\n",
        "        log,\n",
        "        method=method,\n",
        "        N=N,\n",
        "        D=D,\n",
        "        seed=seed,\n",
        "        optimizer_name=optimizer_name,\n",
        "        outdir=outdir,\n",
        "        shots=shots\n",
        "    )\n",
        "    print(f\"[resume] Appended {len(log.exp_values)} iters starting from {info['start_iter']}.\")\n",
        "    return info, log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS7Q9Xo4gvp2"
      },
      "outputs": [],
      "source": [
        "# Load initial parameters\n",
        "theta_init_by_seed = []\n",
        "for i in range(10):\n",
        "  a = torch.load(f\"/content/drive/MyDrive/TRVQA/benchmark/theta_inits/theta_init_s{i}.pt\")\n",
        "  b = torch.load(f\"/content/drive/MyDrive/TRVQA/benchmark/theta_inits/theta_init_s{i}_extra.pt\")\n",
        "  theta_init_by_seed.append(torch.cat([a,b]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdEI2OeEWQK4",
        "outputId": "0405c988-481d-409a-e982-96bc12776e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: {1: {'weight': 38.0}, 2: {'weight': 13.0}, 3: {'weight': 24.0}, 4: {'weight': 73.0}, 5: {'weight': 47.0}, 6: {'weight': 32.0}}, 1: {0: {'weight': 38.0}, 2: {'weight': 50.0}, 3: {'weight': 28.0}, 4: {'weight': 42.0}, 5: {'weight': 57.0}, 6: {'weight': 6.0}}, 2: {0: {'weight': 13.0}, 1: {'weight': 50.0}, 3: {'weight': 32.0}, 4: {'weight': 82.0}, 5: {'weight': 53.0}, 6: {'weight': 44.0}}, 3: {0: {'weight': 24.0}, 1: {'weight': 28.0}, 2: {'weight': 32.0}, 4: {'weight': 51.0}, 5: {'weight': 65.0}, 6: {'weight': 22.0}}, 4: {0: {'weight': 73.0}, 1: {'weight': 42.0}, 2: {'weight': 82.0}, 3: {'weight': 51.0}, 5: {'weight': 99.0}, 6: {'weight': 45.0}}, 5: {0: {'weight': 47.0}, 1: {'weight': 57.0}, 2: {'weight': 53.0}, 3: {'weight': 65.0}, 4: {'weight': 99.0}, 6: {'weight': 55.0}}, 6: {0: {'weight': 32.0}, 1: {'weight': 6.0}, 2: {'weight': 44.0}, 3: {'weight': 22.0}, 4: {'weight': 45.0}, 5: {'weight': 55.0}}}\n"
          ]
        }
      ],
      "source": [
        "with open(\"benchmark/experiment_grid_tsp.json\", \"r\") as f:\n",
        "    loaded = json.load(f)\n",
        "\n",
        "def keys_to_int(d):\n",
        "    \"\"\"Recursively convert all string keys that look like integers to int.\"\"\"\n",
        "    if isinstance(d, dict):\n",
        "        new_dict = {}\n",
        "        for k, v in d.items():\n",
        "            # Convert numeric string keys to int\n",
        "            new_key = int(k) if isinstance(k, str) and k.isdigit() else k\n",
        "            new_dict[new_key] = keys_to_int(v)\n",
        "        return new_dict\n",
        "    else:\n",
        "        return d\n",
        "\n",
        "exp_grid_loaded = [keys_to_int(entry) for entry in loaded]\n",
        "\n",
        "print(exp_grid_loaded[50]['G'])  # should match your original structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4mDv5acBp8j",
        "outputId": "4feb06f1-9947-4c37-dc1c-3183b01265d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49\n"
          ]
        }
      ],
      "source": [
        "N_list_tsp = [4, 9, 16, 25, 36, 49, 64, 81, 100]  # your Ns\n",
        "print(N_list_tsp[5])\n",
        "from qiskit_optimization.applications import Tsp\n",
        "import networkx as nx\n",
        "from qiskit_optimization.converters import QuadraticProgramToQubo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlQEYN6JTORh"
      },
      "outputs": [],
      "source": [
        "from optimization.optimizer import Optimizer\n",
        "import torch\n",
        "\n",
        "optimizer_configs = [\n",
        "    {\n",
        "        \"name\": \"RMSprop_003\",\n",
        "        \"wrapper\": Optimizer(torch.optim.RMSprop, {\n",
        "            \"lr\": 0.05,\n",
        "            \"alpha\": 0.95,\n",
        "            \"eps\": 1e-8,\n",
        "            \"weight_decay\": 0.0,\n",
        "        })\n",
        "    },\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Soxbj4cICo",
        "outputId": "6831cb0e-05f5-4590-801c-b16307e86bf5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Graph 0] D=6, seed=0, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=0, optimizer=RMSprop_003).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-764368160.py:71: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  coefficients.append(float(coeff))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: [=============================>] 99% | ETA: 00:32 | Loss: -149807.6406[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '2cdea0d8', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_2cdea0d8.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_2cdea0d8.csv', 'start_iter': 0}\n",
            "[Graph 0] D=6, seed=0, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] Loaded previous theta for (tr_correct_sampling, N=49, seed=0, optimizer=RMSprop_003).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-764368160.py:71: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  coefficients.append(float(coeff))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: [=============================>] 99% | ETA: 00:18 | Loss: -7068.8074[resume] Appended 100 iters starting from 100.\n",
            "updated files: {'run_id': '65f6a5e6', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_65f6a5e6.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_65f6a5e6.csv', 'start_iter': 100}\n",
            "[Graph 1] D=6, seed=1, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:32 | Loss: -144806.0000[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'a86cce2d', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_a86cce2d.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_a86cce2d.csv', 'start_iter': 0}\n",
            "[Graph 1] D=6, seed=1, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:18 | Loss: -12874.5752[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'b0c56cca', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_b0c56cca.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_b0c56cca.csv', 'start_iter': 0}\n",
            "[Graph 2] D=6, seed=2, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:32 | Loss: -92357.7656[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'fba8a13d', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_fba8a13d.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_fba8a13d.csv', 'start_iter': 0}\n",
            "[Graph 2] D=6, seed=2, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:18 | Loss: -18158.4788[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '3a4365f9', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_3a4365f9.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_3a4365f9.csv', 'start_iter': 0}\n",
            "[Graph 0] D=5, seed=0, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:26 | Loss: -131124.6094[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '637beaa9', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_637beaa9.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_637beaa9.csv', 'start_iter': 0}\n",
            "[Graph 0] D=5, seed=0, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:15 | Loss: -13007.2693[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'a4a4ddb7', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_a4a4ddb7.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_a4a4ddb7.csv', 'start_iter': 0}\n",
            "[Graph 1] D=5, seed=1, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:26 | Loss: -237075.5625[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '10658fdc', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_10658fdc.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_10658fdc.csv', 'start_iter': 0}\n",
            "[Graph 1] D=5, seed=1, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:15 | Loss: -3741.9832[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'f139fe7e', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_f139fe7e.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_f139fe7e.csv', 'start_iter': 0}\n",
            "[Graph 2] D=5, seed=2, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:26 | Loss: -175472.3906[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '6f49d0cb', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_6f49d0cb.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_6f49d0cb.csv', 'start_iter': 0}\n",
            "[Graph 2] D=5, seed=2, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:15 | Loss: -27747.8229[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'e8994cc7', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_e8994cc7.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_e8994cc7.csv', 'start_iter': 0}\n",
            "[Graph 0] D=4, seed=0, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:21 | Loss: -212239.0156[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '647b7978', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_647b7978.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_647b7978.csv', 'start_iter': 0}\n",
            "[Graph 0] D=4, seed=0, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:12 | Loss: -8786.0521[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '5bd90347', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_5bd90347.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_5bd90347.csv', 'start_iter': 0}\n",
            "[Graph 1] D=4, seed=1, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:21 | Loss: -184964.6250[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'ac5c3b64', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_ac5c3b64.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_ac5c3b64.csv', 'start_iter': 0}\n",
            "[Graph 1] D=4, seed=1, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:12 | Loss: -24364.4683[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'db3dfb79', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_db3dfb79.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_db3dfb79.csv', 'start_iter': 0}\n",
            "[Graph 2] D=4, seed=2, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:21 | Loss: -314789.2188[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'd2b4d420', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_d2b4d420.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_d2b4d420.csv', 'start_iter': 0}\n",
            "[Graph 2] D=4, seed=2, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:12 | Loss: -13880.7959[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '9f02653a', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_9f02653a.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_9f02653a.csv', 'start_iter': 0}\n",
            "[Graph 0] D=3, seed=0, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:15 | Loss: -442988.1250[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '82da5fba', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_82da5fba.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_82da5fba.csv', 'start_iter': 0}\n",
            "[Graph 0] D=3, seed=0, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:08 | Loss: -34359.1948[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'f27847c1', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_f27847c1.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_f27847c1.csv', 'start_iter': 0}\n",
            "[Graph 1] D=3, seed=1, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:15 | Loss: -444705.4375[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '250709eb', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_250709eb.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_250709eb.csv', 'start_iter': 0}\n",
            "[Graph 1] D=3, seed=1, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:08 | Loss: -33006.1135[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'dc7caefd', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_dc7caefd.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_dc7caefd.csv', 'start_iter': 0}\n",
            "[Graph 2] D=3, seed=2, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:15 | Loss: -436036.7812[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '945fee16', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_945fee16.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_945fee16.csv', 'start_iter': 0}\n",
            "[Graph 2] D=3, seed=2, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:08 | Loss: -43606.6472[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '43bd642b', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_43bd642b.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_43bd642b.csv', 'start_iter': 0}\n",
            "[Graph 0] D=2, seed=0, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:10 | Loss: -266889.1875[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '44937f2f', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_44937f2f.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_44937f2f.csv', 'start_iter': 0}\n",
            "[Graph 0] D=2, seed=0, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:05 | Loss: -66191.0058[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'b6290185', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_b6290185.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_b6290185.csv', 'start_iter': 0}\n",
            "[Graph 1] D=2, seed=1, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:10 | Loss: -251652.4062[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'a85ae3cc', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_a85ae3cc.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_a85ae3cc.csv', 'start_iter': 0}\n",
            "[Graph 1] D=2, seed=1, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:05 | Loss: -87788.5793[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'cb79375a', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_cb79375a.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_cb79375a.csv', 'start_iter': 0}\n",
            "[Graph 2] D=2, seed=2, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:10 | Loss: -295704.9688[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '9fa75f53', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_9fa75f53.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_9fa75f53.csv', 'start_iter': 0}\n",
            "[Graph 2] D=2, seed=2, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:05 | Loss: -75666.2698[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'd986dbb5', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_d986dbb5.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_d986dbb5.csv', 'start_iter': 0}\n",
            "[Graph 0] D=1, seed=0, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:05 | Loss: -801044.3125[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '936dabbb', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_936dabbb.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_936dabbb.csv', 'start_iter': 0}\n",
            "[Graph 0] D=1, seed=0, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=0, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:02 | Loss: -868078.6218[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'adfe3d45', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_adfe3d45.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_adfe3d45.csv', 'start_iter': 0}\n",
            "[Graph 1] D=1, seed=1, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:05 | Loss: -735076.9375[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '66bb0ce2', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_66bb0ce2.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_66bb0ce2.csv', 'start_iter': 0}\n",
            "[Graph 1] D=1, seed=1, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=1, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:02 | Loss: -978022.5119[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'abf44092', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_abf44092.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_abf44092.csv', 'start_iter': 0}\n",
            "[Graph 2] D=1, seed=2, N=49, method=tr_efficient, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_efficient, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:05 | Loss: -1147195.5000[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': 'b2b42026', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_b2b42026.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_b2b42026.csv', 'start_iter': 0}\n",
            "[Graph 2] D=1, seed=2, N=49, method=tr_correct_sampling, optimizer=RMSprop_003\n",
            "[resume] No previous run found; starting fresh for (tr_correct_sampling, N=49, seed=2, optimizer=RMSprop_003).\n",
            "Progress: [=============================>] 99% | ETA: 00:02 | Loss: -1318481.6742[resume] Appended 100 iters starting from 0.\n",
            "updated files: {'run_id': '08304108', 'theta_path': 'bench_tsp_shot_diff_49_real/theta_08304108.pt', 'iter_csv': 'bench_tsp_shot_diff_49_real/iter_08304108.csv', 'start_iter': 0}\n"
          ]
        }
      ],
      "source": [
        "for target_N in [49]:\n",
        "  graph_lookup = {(g['N'], g['graph_id']): g['G'] for g in exp_grid_loaded}\n",
        "  for D in [6,5,4,3,2,1]:\n",
        "      for seed in [0,1,2]:\n",
        "        for shots in [int(1e3)]:\n",
        "          g = graph_lookup[(target_N, seed)]\n",
        "          N = target_N\n",
        "          param_size = 2 * D * N\n",
        "          theta0 = theta_init_by_seed[seed][:param_size]\n",
        "          #for meth in [\"tr_correct_sampling\"]:\n",
        "          for meth in [\"tr_efficient\" ,\"tr_correct_sampling\"]:\n",
        "              for opt_cfg in optimizer_configs:\n",
        "                  # Create parameter tensor\n",
        "                  theta = theta0.clone().detach().requires_grad_(True)\n",
        "\n",
        "                  # ✅ Build optimizer object from wrapper\n",
        "                  optimizer = opt_cfg[\"wrapper\"]\n",
        "\n",
        "                  print(f\"[Graph {seed}] D={D}, seed={seed}, N={N}, \"\n",
        "                        f\"method={meth}, optimizer={opt_cfg['name']}\")\n",
        "\n",
        "                  info, log = benchmark_resume_inplace(\n",
        "                      method=meth,\n",
        "                      edges=g,\n",
        "                      N=N,\n",
        "                      D=D,\n",
        "                      extra_iter_steps=100,\n",
        "                      seed=seed,\n",
        "                      optimizer_name=opt_cfg[\"name\"],  # logged in summary.csv\n",
        "                      optimizer=optimizer,             # actual optimizer object\n",
        "                      theta_fallback=theta,\n",
        "                      rank=10,\n",
        "                      isRing=True,\n",
        "                      #lr_tr=0.1,  # for convenience\n",
        "                      shots=shots,\n",
        "                      outdir=\"bench_tsp_shot_diff_49_real\",\n",
        "                      batch_size_ef=200,\n",
        "                      batch_size_cs=700,\n",
        "                      batch_size_ps=1000,\n",
        "                  )\n",
        "\n",
        "                  torch.cuda.empty_cache()\n",
        "                  print(\"updated files:\", info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAVPGOgb7U55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c8f66c-7c45-479f-f298-7d8b6cf2f45b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "84"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP1jdXW4hZK5"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}