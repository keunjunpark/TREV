{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCFiaasfzDeY",
        "outputId": "76e7978b-cd98-4b30-a918-ced33993d1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.43.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.5)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray==0.8.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.43 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.43.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning>=0.43->pennylane) (0.3.30.0.4)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.10.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.17.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.2)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: qiskit_aer in /usr/local/lib/python3.12/dist-packages (0.17.2)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from qiskit_aer) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.12/dist-packages (from qiskit_aer) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.12/dist-packages (from qiskit_aer) (1.16.2)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from qiskit_aer) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit_aer) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit_aer) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.1.0->qiskit_aer) (0.17.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.1.0->qiskit_aer) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.1.0->qiskit_aer) (5.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit>=1.1.0->qiskit_aer) (4.15.0)\n",
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.12/dist-packages (12.0.3)\n",
            "Requirement already satisfied: tensorcircuit in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorcircuit) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from tensorcircuit) (1.16.2)\n",
            "Requirement already satisfied: tensornetwork-ng in /usr/local/lib/python3.12/dist-packages (from tensorcircuit) (0.5.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from tensorcircuit) (3.5)\n",
            "Requirement already satisfied: graphviz>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from tensornetwork-ng->tensorcircuit) (0.21)\n",
            "Requirement already satisfied: opt-einsum>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from tensornetwork-ng->tensorcircuit) (3.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from tensornetwork-ng->tensorcircuit) (3.15.1)\n",
            "Requirement already satisfied: quimb in /usr/local/lib/python3.12/dist-packages (1.11.2)\n",
            "Requirement already satisfied: autoray>=0.6.12 in /usr/local/lib/python3.12/dist-packages (from quimb) (0.8.0)\n",
            "Requirement already satisfied: cotengra>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from quimb) (0.7.5)\n",
            "Requirement already satisfied: cytoolz>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from quimb) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.39 in /usr/local/lib/python3.12/dist-packages (from quimb) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from quimb) (2.0.2)\n",
            "Requirement already satisfied: psutil>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from quimb) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from quimb) (1.16.2)\n",
            "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.12/dist-packages (from quimb) (4.67.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from cytoolz>=0.8.0->quimb) (0.12.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.39->quimb) (0.43.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane\n",
        "!pip install qiskit\n",
        "!pip install qiskit_aer\n",
        "!pip install gurobipy\n",
        "!pip install tensorcircuit\n",
        "!pip install quimb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gFmzOrI36gz",
        "outputId": "4d7fc9c9-05a7-4ce7-8341-d6cc95a75d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:9: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:9: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-2251797223.py:9: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  sys.path.append('/content/drive/My\\ Drive/TRVQA')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/TRVQA\n",
            "bench_10S_10I\t\t       bench_out_comparison_gpu\n",
            "bench_10S_10I_start\t       bench_out_pl\n",
            "benchmark\t\t       bench_out_shot_diff\n",
            "bench_out\t\t       bench_out_shot_diff_2436\n",
            "bench_out_100\t\t       bench_out_shot_diff_24_real\n",
            "bench_out_1000\t\t       bench_out_shot_diff_36_real\n",
            "bench_out_100_old\t       bench_out_shot_diff_4816_real\n",
            "bench_out_150\t\t       bench_out_shot_diff_52\n",
            "bench_out_2436\t\t       bench_out_shot_diff_52_real\n",
            "bench_out_4816\t\t       bench_tsp_4816\n",
            "bench_out_4816_lr_3\t       bench_tsp_49\n",
            "bench_out_4816_old\t       circuit.py\n",
            "bench_out_4816_sv_compare      ex_value_pots\n",
            "bench_out_52\t\t       gates\n",
            "bench_out_52_lr\t\t       hamiltonian\n",
            "bench_out_52_memory\t       __init__.py\n",
            "bench_out_52_old\t       measure\n",
            "bench_out_52_opt\t       optimization\n",
            "bench_out_comparison\t       __pycache__\n",
            "bench_out_comparison_cpu_real  utils\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/TRVQA\n",
        "\n",
        "# List files to make sure we're in the expected directory.\n",
        "# Your output will look different, showing your own Drive files here.\n",
        "!ls\n",
        "import sys\n",
        "sys.path.append('/content/drive/My\\ Drive/TRVQA')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkJjOoej4o85"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import sys\n",
        "import os\n",
        "# Add the parent directory of TRVQA to sys.path\n",
        "from measure.enums import MeasureMethod\n",
        "from optimization.gradients.vanilla_parameter_shift import vanilla_parameter_shift\n",
        "from optimization.optimization import minimize, minimize_custom\n",
        "#from utils.maxcut import gengraph, create_hamiltonian, make_hamiltonian\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from qiskit.circuit.library import QAOAAnsatz\n",
        "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from circuit import Circuit\n",
        "\n",
        "def compute_maxcut_value(bitstring, graph):\n",
        "    \"\"\"Computes the MaxCut value for a given bitstring solution.\"\"\"\n",
        "    cut_value = sum(w for (u,v), w in graph if bitstring[u] != bitstring[v])\n",
        "    return cut_value\n",
        "\n",
        "# for s in best_value:\n",
        "#     print(compute_maxcut_value(s, g))\n",
        "\n",
        "from pyparsing import Optional\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp\n",
        "from optimization.optimization import minimize, minimize_custom\n",
        "# TRVQA imports\n",
        "\n",
        "from circuit import Circuit\n",
        "from hamiltonian.hamiltonian import Hamiltonian\n",
        "from measure.enums import MeasureMethod\n",
        "torch.cuda.empty_cache()\n",
        "import numpy as np\n",
        "import torch\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp\n",
        "import torch\n",
        "\n",
        "from measure.enums import MeasureMethod\n",
        "from optimization.optimization import minimize\n",
        "from utils.maxcut import gengraph, create_hamiltonian,make_hamiltonian\n",
        "from hamiltonian.hamiltonian import Hamiltonian\n",
        "import numpy as np\n",
        "import torch\n",
        "from circuit import Circuit\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg2rgDKO3pSb"
      },
      "outputs": [],
      "source": [
        "# Load initial parameters\n",
        "theta_init_by_seed = []\n",
        "for i in range(10):\n",
        "  a = torch.load(f\"/content/drive/MyDrive/TRVQA/benchmark/theta_inits/theta_init_s{i}.pt\")\n",
        "  b = torch.load(f\"/content/drive/MyDrive/TRVQA/benchmark/theta_inits/theta_init_s{i}_extra.pt\")\n",
        "  theta_init_by_seed.append(torch.cat([a,b]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdgfehgY3qHg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"benchmark/experiment_grid.json\", \"r\") as f:\n",
        "    loaded = json.load(f)\n",
        "\n",
        "# Convert lists back to tuples if you want\n",
        "def convert_lists_to_tuples(obj):\n",
        "    if isinstance(obj, list):\n",
        "        # Check if list looks like an edge [(0,1), w]\n",
        "        if len(obj) == 2 and isinstance(obj[0], list) and isinstance(obj[1], (int, float)):\n",
        "            return (tuple(obj[0]), obj[1])\n",
        "        else:\n",
        "            return [convert_lists_to_tuples(x) for x in obj]\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: convert_lists_to_tuples(v) for k, v in obj.items()}\n",
        "    return obj\n",
        "\n",
        "graph_by_seed = [convert_lists_to_tuples(entry) for entry in loaded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilYSxA-h9mBz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, csv, json, time, uuid\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, List, Optional\n",
        "\n",
        "# 1) RunLog (same shape you specified)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "@dataclass\n",
        "class RunLog:\n",
        "    exp_values: List[float]        # e.g., energies (float-able)\n",
        "    best_results: List[Any]        # optional bitstrings/ints/etc.\n",
        "    iter_times: List[float]        # per-iteration wall times (s)\n",
        "    final_theta: torch.Tensor      # final parameter vector (Tensor)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2) Minimal CSV summary + iter I/O (only library, N, D)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def _read_summary_slim(summary_csv: str) -> List[dict]:\n",
        "    if not os.path.exists(summary_csv):\n",
        "        return []\n",
        "    with open(summary_csv, \"r\", newline=\"\") as f:\n",
        "        return list(csv.DictReader(f))\n",
        "\n",
        "def _write_summary_header_if_missing_slim(summary_csv: str) -> None:\n",
        "    if not os.path.exists(summary_csv):\n",
        "        os.makedirs(os.path.dirname(summary_csv), exist_ok=True)\n",
        "        with open(summary_csv, \"w\", newline=\"\") as f:\n",
        "            csv.writer(f).writerow([\n",
        "                \"run_id\", \"library\", \"N\", \"depth\", \"seed\",\n",
        "                \"theta_path\", \"iter_csv\"\n",
        "            ])\n",
        "\n",
        "def _find_run_row_slim(\n",
        "    library: str, N: int, D: int,seed: int, summary_csv: str\n",
        ") -> Optional[dict]:\n",
        "    rows = _read_summary_slim(summary_csv)\n",
        "    cand = [r for r in rows\n",
        "            if r[\"library\"] == library\n",
        "            and int(r[\"N\"]) == N\n",
        "            and int(r[\"depth\"]) == D\n",
        "            and int(r['seed']) == seed]\n",
        "    return cand[-1] if cand else None\n",
        "\n",
        "def _read_last_iter(iter_csv_path: str) -> int:\n",
        "    if not os.path.exists(iter_csv_path):\n",
        "        return -1\n",
        "    last = -1\n",
        "    with open(iter_csv_path, \"r\", newline=\"\") as f:\n",
        "        r = csv.DictReader(f)\n",
        "        for row in r:\n",
        "            last = int(row[\"iter\"])\n",
        "    return last\n",
        "\n",
        "def _overwrite_row_slim(updated_row: dict, summary_csv: str) -> None:\n",
        "    rows = _read_summary_slim(summary_csv)\n",
        "    for i, r in enumerate(rows):\n",
        "        if r[\"run_id\"] == updated_row[\"run_id\"]:\n",
        "            rows[i] = updated_row\n",
        "            break\n",
        "    with open(summary_csv, \"w\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=[\"run_id\",\"library\",\"N\",\"depth\",\"seed\", \"theta_path\",\"iter_csv\"])\n",
        "        w.writeheader()\n",
        "        w.writerows(rows)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 3) Append-in-place (SLIM)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def append_run_inplace_slim(\n",
        "    runlog: RunLog,\n",
        "    *,\n",
        "    library: str,            # e.g., \"tensorcircuit\"\n",
        "    N: int,\n",
        "    D: int,\n",
        "    seed: int,\n",
        "    outdir: str = \"bench_out_comparison\",\n",
        "    summary_csv: str = \"bench_out_comparison/summary.csv\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Append iterations to the (library, N, D) run; create it if missing.\n",
        "    Only keeps minimal fields: library, N, depth, theta_path, iter_csv.\n",
        "    \"\"\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    _write_summary_header_if_missing_slim(summary_csv)\n",
        "\n",
        "    row = _find_run_row_slim(library, N, D, seed, summary_csv)\n",
        "    if row is None:\n",
        "        run_id = str(uuid.uuid4())[:8]\n",
        "        theta_path = os.path.join(outdir, f\"theta_{run_id}.pt\")\n",
        "        iter_csv_path = os.path.join(outdir, f\"iter_{run_id}.csv\")\n",
        "        # create iter CSV with header\n",
        "        with open(iter_csv_path, \"w\", newline=\"\") as f:\n",
        "            w = csv.writer(f); w.writerow([\"iter\",\"exp_value\",\"best_result\",\"iter_time\"])\n",
        "        # add to summary\n",
        "        with open(summary_csv, \"a\", newline=\"\") as f:\n",
        "            w = csv.writer(f)\n",
        "            w.writerow([run_id, library, N, D, seed, theta_path, iter_csv_path])\n",
        "        start_iter = 0\n",
        "    else:\n",
        "        run_id      = row[\"run_id\"]\n",
        "        theta_path  = row[\"theta_path\"]\n",
        "        iter_csv_path = row[\"iter_csv\"]\n",
        "        start_iter = _read_last_iter(iter_csv_path) + 1\n",
        "\n",
        "    # Append iterations\n",
        "    with open(iter_csv_path, \"a\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        for i, (e, b, t) in enumerate(zip(runlog.exp_values, runlog.best_results, runlog.iter_times)):\n",
        "            w.writerow([start_iter + i, e, json.dumps(b), t])\n",
        "\n",
        "    # Save final theta\n",
        "    torch.save(runlog.final_theta.detach().cpu(), theta_path)\n",
        "\n",
        "    return {\n",
        "        \"run_id\": run_id,\n",
        "        \"theta_path\": theta_path,\n",
        "        \"iter_csv\": iter_csv_path,\n",
        "        \"start_iter\": start_iter,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "NCvHwqNyS5TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdFtyr1ZBhj9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "outputId": "4a291d7f-3503-4546-9c24-79a25ecf4682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Ipython in /usr/local/lib/python3.12/dist-packages (7.34.0)\n",
            "Collecting Ipython\n",
            "  Downloading ipython-9.6.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from Ipython) (4.4.2)\n",
            "Collecting ipython-pygments-lexers (from Ipython)\n",
            "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jedi>=0.16 (from Ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from Ipython) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from Ipython) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from Ipython) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from Ipython) (2.19.2)\n",
            "Collecting stack_data (from Ipython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.13.0 (from Ipython)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->Ipython) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->Ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->Ipython) (0.2.14)\n",
            "Collecting executing>=1.2.0 (from stack_data->Ipython)\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->Ipython)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->Ipython)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading ipython-9.6.0-py3-none-any.whl (616 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m616.2/616.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pure-eval, traitlets, jedi, ipython-pygments-lexers, executing, asttokens, stack_data, Ipython\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: Ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 9.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Ipython-9.6.0 asttokens-3.0.0 executing-2.2.1 ipython-pygments-lexers-1.1.1 jedi-0.19.2 pure-eval-0.2.3 stack_data-0.6.3 traitlets-5.14.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "traitlets"
                ]
              },
              "id": "44d1c6e45c334d75b8c3dc88f54172b9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install Ipython --upgrade\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx5_-fG6DF-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198a1b30-51df-4810-8993-18e5fdb0b080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorcircuit.translation:Please first ``pip install -U qiskit`` to enable related functionality in translation module\n",
            "WARNING:tensorcircuit.translation:Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
          ]
        }
      ],
      "source": [
        "from tensorcircuit import backends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2E7LH1f941w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import tensorcircuit as tc\n",
        "import torch\n",
        "\n",
        "import tensorcircuit as tc\n",
        "# make sure you're on torch backend *before* building circuits\n",
        "tc.set_backend(\"pytorch\")\n",
        "\n",
        "def build_ansatz_tc_pytorch(theta, N, D, use_mps):\n",
        "    # theta: torch.Tensor with requires_grad=True\n",
        "    th = theta.reshape(-1)  # flat view (no copy)\n",
        "\n",
        "    c = tc.MPSCircuit(N) if use_mps else tc.Circuit(N)\n",
        "    if use_mps:\n",
        "        c.set_split_rules({\"max_singular_values\": 10})  # optional; beware aggressive truncation\n",
        "\n",
        "    k = 0\n",
        "    for _ in range(D):\n",
        "        for i in range(N):\n",
        "            # ‚ùå was: c.rx(i, theta=theta[k].item())  -> breaks graph\n",
        "            c.rx(i, theta=th[k])                      # ‚úÖ keep tensor\n",
        "            k += 1\n",
        "        for i in range(N):\n",
        "            c.rz(i, theta=th[k])                      # ‚úÖ keep tensor\n",
        "            k += 1\n",
        "        for i in range(N - 1):\n",
        "            c.cx(i, i + 1)\n",
        "        c.cx(N - 1, 0)\n",
        "    return c\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "import tensorcircuit as tc\n",
        "K = tc.set_backend(\"pytorch\")  # 1) ensure torch backend\n",
        "# If you're using TensorCircuit:\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 4) Your benchmark: now returns RunLog and (optionally) saves via slim appender\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def benchmark_tensorcircuit_tc_pytorch(\n",
        "    graph, D,seed, steps, use_mps, device, theta, lr=0.1,\n",
        "    *,\n",
        "    library_name: str = \"tensorcircuit\",\n",
        "    save: bool = True,\n",
        "    outdir: str = \"bench_out_comparison\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs a simple VQE loop in TensorCircuit and collects a RunLog.\n",
        "    If save=True, appends to (library_name, N, D) run using the slim CSV logger.\n",
        "    \"\"\"\n",
        "    # infer N from edges\n",
        "    N = max(max(u, v) for (u, v), _ in graph) + 1\n",
        "    print(f\"\\nüöÄ TensorCircuit VQE | N={N} | {'matrix_product_state' if use_mps else 'full'} Circuit,  {'CPU' if device == 'cpu' else 'GPU'} backend\")\n",
        "\n",
        "    # build Ising-like H from edges list -> list[(weight, mask)]\n",
        "    hm_terms = create_hamiltonian(N, graph)  # expects same shape as your original helper\n",
        "    theta = theta.detach().clone().requires_grad_(True)  #\n",
        "    # params\n",
        "    num_params = D * 2 * N\n",
        "    # theta_np = np.random.randn(num_params)\n",
        "    # theta = tc.backend.convert_to_tensor(theta_np)\n",
        "    def energy_from_theta(th):\n",
        "      # returns a real torch scalar\n",
        "      energy = torch.zeros((), dtype=th.real.dtype, device=th.device)\n",
        "      c = build_ansatz_tc_pytorch(th, N, D, use_mps=True)  # stays MPS\n",
        "      for weight, mask in hm_terms:\n",
        "          z_idx = [i for i, v in enumerate(mask) if v]\n",
        "          if z_idx:\n",
        "              e = c.expectation_ps(z=z_idx)\n",
        "              energy = energy + torch.as_tensor(weight, dtype=energy.dtype, device=th.device) * torch.real(e)\n",
        "          else:\n",
        "              energy = energy + torch.as_tensor(weight, dtype=energy.dtype, device=th.device)\n",
        "      return energy\n",
        "\n",
        "    \"\"\"\n",
        "    RuntimeError: svd_backward: The singular vectors in the\n",
        "     complex case are specified up to multiplication by e^{i phi}.\n",
        "     The specified loss function depends on this phase term, making it ill-defined.\n",
        "    \"\"\"\n",
        "    # ‚îÄ‚îÄ Ansatz + loss\n",
        "    @torch.no_grad()\n",
        "    def parameter_shift_grad(th, shift=math.pi/2):\n",
        "        \"\"\"\n",
        "        Standard parameter-shift for gates with generator eigenvalues ¬±1/2 (RX/RZ, etc.).\n",
        "        Returns grad with same shape as th. Uses 2 evals per parameter.\n",
        "        \"\"\"\n",
        "        th = th.detach().clone().requires_grad_(False)\n",
        "        grad = torch.zeros_like(th, dtype=th.dtype)\n",
        "        # vectorized over parameters via in-place add/sub per index\n",
        "        for i in range(th.numel()):\n",
        "            th[i] += shift\n",
        "            Ep = energy_from_theta(th)\n",
        "            th[i] -= 2*shift\n",
        "            Em = energy_from_theta(th)\n",
        "            th[i] += shift  # restore\n",
        "            # (Ep - Em) / 2  for generators with ¬±1/2 spectrum (RX/RZ)\n",
        "            grad[i] = (Ep - Em) * 0.5\n",
        "        return grad\n",
        "    def loss_fn(th):\n",
        "        # real scalar accumulator on the right device/dtype\n",
        "        energy = torch.zeros((), dtype=th.real.dtype, device=th.device)\n",
        "\n",
        "        c = build_ansatz_tc_pytorch(th, N, D, use_mps)\n",
        "\n",
        "        for weight, mask in hm_terms:\n",
        "            z_idx = [i for i, v in enumerate(mask) if v]\n",
        "            if z_idx:\n",
        "                e_term = c.expectation_ps(z=z_idx)     # may be complex64\n",
        "                e_term = torch.real(e_term)            # keep graph, drop tiny imag part\n",
        "                w = torch.as_tensor(weight, dtype=energy.dtype, device=th.device)\n",
        "                energy = energy + w * e_term\n",
        "            else:\n",
        "                energy = energy + torch.as_tensor(weight, dtype=energy.dtype, device=th.device)\n",
        "\n",
        "        return energy  # real torch scalar (required for autograd)\n",
        "\n",
        "    vg_fn = tc.backend.value_and_grad(loss_fn)\n",
        "    exp_values: List[float] = []\n",
        "    best_results: List[Any] = []      # You can push argmin bitstrings here if/when you have them\n",
        "    iter_times: List[float] = []\n",
        "\n",
        "    best_energy = float(\"inf\")\n",
        "    best_any: Any = None\n",
        "\n",
        "    for step in range(steps):\n",
        "        t0 = time.time()\n",
        "        energy = loss_fn(theta)               # scalar (TensorCircuit backend scalar)\n",
        "        if use_mps:\n",
        "            grad = parameter_shift_grad(theta)\n",
        "        else:\n",
        "          energy, grad  = vg_fn(theta)                 # same shape as theta\n",
        "        with torch.no_grad():\n",
        "            theta -= lr * grad\n",
        "        dt = time.time() - t0\n",
        "        theta.requires_grad_(True)\n",
        "        # record\n",
        "        energy_float = float(np.real(energy))\n",
        "        exp_values.append(energy_float)\n",
        "        iter_times.append(dt)\n",
        "        best_results.append(best_any)         # keep None/placeholder or plug real best if you track it\n",
        "\n",
        "        if energy_float < best_energy:\n",
        "            best_energy = energy_float\n",
        "            best_any = {\"step\": step, \"energy\": best_energy}\n",
        "\n",
        "        #print(f\"Step {step:2d}: E={energy_float:.6f} | t={dt:.3f}s\")\n",
        "\n",
        "    # Final Œ∏ back to torch tensor for consistency with your RunLog\n",
        "    final_theta_torch = theta.detach().clone()\n",
        "\n",
        "    runlog = RunLog(\n",
        "        exp_values=[float(v) for v in exp_values],\n",
        "        best_results=list(best_results),\n",
        "        iter_times=list(iter_times),\n",
        "        final_theta=final_theta_torch,\n",
        "    )\n",
        "\n",
        "    #print(f\"‚è±Ô∏è Avg time/step: {np.mean(iter_times):.3f}s ¬± {np.std(iter_times):.3f}\")\n",
        "\n",
        "    # save (slim)\n",
        "    info = None\n",
        "    if save:\n",
        "        info = append_run_inplace_slim(\n",
        "            runlog,\n",
        "            library=library_name,\n",
        "            N=N,\n",
        "            D=D,\n",
        "            seed = seed,\n",
        "            outdir=outdir,\n",
        "            summary_csv=os.path.join(outdir, \"summary.csv\"),\n",
        "        )\n",
        "        print(f\"[append] Appended {len(runlog.exp_values)} iters starting from {info['start_iter']} (run_id={info['run_id']}).\")\n",
        "\n",
        "    return (info, runlog) if save else runlog\n"
      ],
      "metadata": {
        "id": "z337144aLM27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # edges: [((u,v), weight), ...]; graph helper functions assumed available\n",
        "# graph_lookup = {(g['N'], g['graph_id']): g['G'] for g in graph_by_seed}\n",
        "# info, log = benchmark_tensorcircuit_tc_pytorch(\n",
        "#     graph=graph_lookup[(4,0)],\n",
        "#     D=1,\n",
        "#     steps=1,\n",
        "#     use_mps=True,\n",
        "#     device=\"cuda\",\n",
        "#     lr=0.05,\n",
        "#     library_name=\"tensorcircuit_cpu\",\n",
        "#     save=True,\n",
        "#     outdir=\"bench_out_comparison\"\n",
        "# )\n"
      ],
      "metadata": {
        "id": "02sia_NsLRJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import pennylane as qml\n",
        "from typing import Any, List, Optional\n",
        "\n",
        "# expects you already have:\n",
        "# - RunLog dataclass\n",
        "# - append_run_inplace_slim(...)\n",
        "# - create_hamiltonian(...) and make_hamiltonian(...), sparse_pauliop_to_qml_hamiltonian(...)\n",
        "def sparse_pauliop_to_qml_hamiltonian(sparse_op):\n",
        "    \"\"\"Convert Qiskit SparsePauliOp to PennyLane Hamiltonian.\"\"\"\n",
        "    coeff_list = sparse_op.coeffs.real.tolist()\n",
        "    op_list = []\n",
        "\n",
        "    for pauli_str in sparse_op.paulis.to_labels():\n",
        "        terms = []\n",
        "        for idx, pauli_char in enumerate(pauli_str):\n",
        "            idx = len(pauli_str)-1-idx\n",
        "            if pauli_char == \"I\":\n",
        "                continue\n",
        "            elif pauli_char == \"X\":\n",
        "                terms.append(qml.PauliX(idx))\n",
        "            elif pauli_char == \"Y\":\n",
        "                terms.append(qml.PauliY(idx))\n",
        "            elif pauli_char == \"Z\":\n",
        "                terms.append(qml.PauliZ(idx))\n",
        "        if terms:\n",
        "            op = terms[0]\n",
        "            for term in terms[1:]:\n",
        "                op = op @ term\n",
        "        else:\n",
        "            op = qml.Identity(0)\n",
        "        op_list.append(op)\n",
        "\n",
        "    return qml.Hamiltonian(coeff_list, op_list)\n",
        "def _qml_hamiltonian_from_graph(graph) -> Optional[qml.Hamiltonian]:\n",
        "    \"\"\"\n",
        "    Try to build a PennyLane Hamiltonian from your helpers.\n",
        "    Fallback to Z0 if helpers are missing.\n",
        "    \"\"\"\n",
        "    H_sparse = make_hamiltonian(graph)  # your SparsePauliOp (or similar)\n",
        "    return sparse_pauliop_to_qml_hamiltonian(H_sparse)\n",
        "\n",
        "def _pick_pl_device(device: str) -> str:\n",
        "    \"\"\"\n",
        "    Map torch device string to a PennyLane device name.\n",
        "    Prefer lightning.gpu for cuda; fall back gracefully.\n",
        "    \"\"\"\n",
        "    if device == \"cuda\":\n",
        "        try:\n",
        "            # Try GPU device if available in your env\n",
        "            _ = qml.device(\"lightning.gpu\", wires=1)  # probe\n",
        "            return \"lightning.gpu\"\n",
        "        except Exception:\n",
        "            return \"default.qubit\"\n",
        "    else:\n",
        "        # CPU\n",
        "        try:\n",
        "            _ = qml.device(\"lightning.qubit\", wires=1)\n",
        "            return \"lightning.qubit\"\n",
        "        except Exception:\n",
        "            return \"default.qubit\"\n",
        "\n",
        "def benchmark_pennylane_device(\n",
        "    graph,\n",
        "    theta,\n",
        "    D: int,\n",
        "    seed: int,\n",
        "    steps: int,\n",
        "    use_mps: bool,            # kept for signature compatibility (unused in PL)\n",
        "    device: str,              # \"cpu\" or \"cuda\"\n",
        "    lr: float = 0.1,\n",
        "    *,\n",
        "    library_name: str = \"pennylane\",\n",
        "    save: bool = True,\n",
        "    outdir: str = \"bench_out_pl\"\n",
        "):\n",
        "    \"\"\"\n",
        "    PennyLane benchmark with TensorCircuit-compatible signature.\n",
        "    Returns (info_dict_or_None, RunLog).\n",
        "    \"\"\"\n",
        "    # infer N from edges: graph like [((u,v), w), ...]\n",
        "    N = max(max(u, v) for (u, v), _ in graph) + 1\n",
        "    #pl_dev = _pick_pl_device(device)\n",
        "    pl_dev = device\n",
        "    graph = create_hamiltonian(N,graph)\n",
        "    print(f\"\\n‚öôÔ∏è PennyLane VQE | N={N} | dev={pl_dev} | torch={device} | D={D} | steps={steps}\")\n",
        "\n",
        "    # Try to use your true Hamiltonia n; fallback to Z0\n",
        "    H_qml = _qml_hamiltonian_from_graph(graph)\n",
        "    # if H_qml is None:\n",
        "    #     H_qml = qml.Hamiltonian([1.0], [qml.PauliZ(0)])\n",
        "    #     print(\"  (‚ÑπÔ∏è using fallback H = Z0)\")\n",
        "\n",
        "    dev_pl = qml.device(pl_dev, wires=N)\n",
        "    @qml.qnode(dev_pl, interface=\"torch\", diff_method=\"parameter-shift\")\n",
        "    def circuit(theta):\n",
        "        # theta shape: (D, 2N)\n",
        "        for d in range(D):\n",
        "            for j in range(N):\n",
        "                qml.RX(theta[d, j], wires=j)\n",
        "            for j in range(N):\n",
        "                qml.RZ(theta[d, N + j], wires=j)\n",
        "            for j in range(N - 1):\n",
        "                qml.CNOT(wires=[j, j + 1])\n",
        "            qml.CNOT(wires=[N-1, 0])\n",
        "        return qml.expval(H_qml)\n",
        "\n",
        "    # Œ∏ on requested torch device\n",
        "    # Slice to first 8 elements\n",
        "    theta = theta[:D* 2 * N]  # shape: [8]\n",
        "\n",
        "    # Reshape to [2, 4]\n",
        "    theta = theta.view(D, 2*N).clone().detach().requires_grad_(True)\n",
        "    #print(theta)\n",
        "    #theta = torch.rand((D, 2 * N), dtype=torch.float32, requires_grad=True, device=device)\n",
        "    optimizer = torch.optim.SGD([theta], lr=lr)\n",
        "\n",
        "    exp_values: List[float] = []\n",
        "    best_results: List[Any] = []\n",
        "    iter_times: List[float] = []\n",
        "\n",
        "    best_energy = float(\"inf\")\n",
        "    best_any: Any = None\n",
        "\n",
        "    for step in range(steps):\n",
        "        t0 = time.time()\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        energy = circuit(theta)  # torch scalar\n",
        "        energy.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        dt = time.time() - t0\n",
        "        e_val = float(energy.detach().cpu().item())\n",
        "\n",
        "        exp_values.append(e_val)\n",
        "        iter_times.append(dt)\n",
        "        best_results.append(best_any)\n",
        "\n",
        "        if e_val < best_energy:\n",
        "            best_energy = e_val\n",
        "            best_any = {\"step\": step, \"energy\": best_energy}\n",
        "\n",
        "        #print(f\"Step {step:2d}: E = {e_val:.6f} | t = {dt:.4f}s\")\n",
        "\n",
        "    final_theta_cpu = theta.detach().to(\"cpu\").clone()\n",
        "    runlog = RunLog(\n",
        "        exp_values=[float(v) for v in exp_values],\n",
        "        best_results=list(best_results),\n",
        "        iter_times=list(iter_times),\n",
        "        final_theta=final_theta_cpu,\n",
        "    )\n",
        "\n",
        "    # optional: persist with slim logger (keyed only by library, N, D)\n",
        "    info = None\n",
        "    if save:\n",
        "        info = append_run_inplace_slim(\n",
        "            runlog,\n",
        "            library=f\"{library_name}:{pl_dev}\",\n",
        "            N=N,\n",
        "            D=D,\n",
        "            seed=seed,\n",
        "            outdir=outdir,\n",
        "            summary_csv=f\"{outdir}/summary.csv\",\n",
        "        )\n",
        "        print(f\"[append] Appended {len(runlog.exp_values)} iters starting from {info['start_iter']} (run_id={info['run_id']}).\")\n",
        "\n",
        "    return info, runlog\n"
      ],
      "metadata": {
        "id": "Bdtetbu1PSdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5aff6a-3ed1-433d-d3fb-34789cd278c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from typing import Any, List\n",
        "import numpy as np\n",
        "import time\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit_aer import AerSimulator\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "lr =1e-2\n",
        "def build_ansatz_qiskit(theta, N, D):\n",
        "    qc = QuantumCircuit(N)\n",
        "    for d in range(D):\n",
        "        for j in range(N):\n",
        "            qc.rx(theta[d, j], j)\n",
        "        for j in range(N):\n",
        "            qc.rz(theta[d, N + j], j)\n",
        "        for j in range(N - 1):\n",
        "            qc.cx(j, j + 1)\n",
        "        qc.cx(N-1,0)\n",
        "    return qc\n",
        "def expectation_qiskit(theta, N, D, obs, use_mps, device='CPU'):\n",
        "    qc = build_ansatz_qiskit(theta, N, D)\n",
        "    sim = AerSimulator(method=\"matrix_product_state\" if use_mps else \"statevector\", device=device)\n",
        "    qc.save_statevector()\n",
        "    result = sim.run(qc).result()\n",
        "    sv = result.get_statevector(qc)\n",
        "    return np.real(sv.expectation_value(obs))\n",
        "\n",
        "def parameter_shift_grad(theta, N, D, obs, shift=np.pi/2, use_mps=False, device='CPU'):\n",
        "    grads = np.zeros_like(theta)\n",
        "    for i in range(D):\n",
        "        for j in range(2 * N):\n",
        "            theta_plus = theta.copy(); theta_plus[i, j] += shift\n",
        "            theta_minus = theta.copy(); theta_minus[i, j] -= shift\n",
        "            f_plus = expectation_qiskit(theta_plus, N, D, obs, use_mps, device)\n",
        "            f_minus = expectation_qiskit(theta_minus, N, D, obs, use_mps, device)\n",
        "            grads[i, j] = 0.5 * (f_plus - f_minus)\n",
        "    return grads\n",
        "# expects:\n",
        "# - RunLog dataclass\n",
        "# - append_run_inplace_slim(library, N, D, outdir, summary_csv)\n",
        "# - make_hamiltonian(graph) -> observable for Qiskit\n",
        "# - expectation_qiskit(theta, N, D, obs, use_mps, device) -> float\n",
        "# - parameter_shift_grad(theta, N, D, obs, use_mps, device) -> np.ndarray same shape as theta\n",
        "\n",
        "def benchmark_qiskit_device(\n",
        "    graph,\n",
        "    theta,\n",
        "    D: int,\n",
        "    seed: int,\n",
        "    steps: int,\n",
        "    use_mps: bool,\n",
        "    device: str,               # e.g. \"CPU\" | \"GPU\" | backend name you handle internally\n",
        "    lr: float = 0.1,\n",
        "    *,\n",
        "    library_name: str = \"qiskit\",\n",
        "    save: bool = True,\n",
        "    outdir: str = \"bench_out_qiskit\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Qiskit benchmark with the SAME signature as your TensorCircuit function.\n",
        "    Returns (info_dict_or_None, RunLog).\n",
        "    \"\"\"\n",
        "    # infer N from edges: graph like [((u,v), w), ...]\n",
        "    N = max(max(u, v) for (u, v), _ in graph) + 1\n",
        "    backend_tag = \"mps\" if use_mps else \"statevector\"\n",
        "    print(f\"\\nüîß Qiskit {backend_tag.upper()} | N={N} | Device={device} | D={D} | steps={steps}\")\n",
        "\n",
        "    # Hamiltonian from your helper\n",
        "    obs = create_hamiltonian(N,graph)\n",
        "    obs = make_hamiltonian(obs)\n",
        "\n",
        "    # Œ∏ ‚àà R^{D √ó 2N}\n",
        "    theta = theta[:D* 2 * N]  # shape: [8]\n",
        "\n",
        "    # Reshape to [2, 4]\n",
        "    theta = theta.detach().cpu().numpy().reshape(D, 2 * N).astype(np.float64)\n",
        "    #theta = np.random.rand(D, 2 * N).astype(np.float64)\n",
        "\n",
        "    exp_values: List[float] = []\n",
        "    best_results: List[Any] = []\n",
        "    iter_times: List[float] = []\n",
        "\n",
        "    best_energy = float(\"inf\")\n",
        "    best_any: Any = None\n",
        "\n",
        "    for step in range(steps):\n",
        "        t0 = time.time()\n",
        "\n",
        "        energy = expectation_qiskit(theta, N, D, obs, use_mps=use_mps, device=device)\n",
        "        grad   = parameter_shift_grad(theta, N, D, obs, use_mps=use_mps, device=device)\n",
        "        theta -= lr * grad\n",
        "\n",
        "        dt = time.time() - t0\n",
        "        exp_values.append(float(energy))\n",
        "        iter_times.append(dt)\n",
        "        best_results.append(best_any)\n",
        "\n",
        "        if energy < best_energy:\n",
        "            best_energy = float(energy)\n",
        "            best_any = {\"step\": step, \"energy\": best_energy}\n",
        "\n",
        "        #print(f\"Step {step:2d}: E={float(energy):.6f} | t={dt:.3f}s\")\n",
        "\n",
        "    # Pack as RunLog (final theta as torch tensor for consistency)\n",
        "    final_theta_torch = torch.from_numpy(theta.copy()).detach().clone()\n",
        "    runlog = RunLog(\n",
        "        exp_values=[float(v) for v in exp_values],\n",
        "        best_results=list(best_results),\n",
        "        iter_times=list(iter_times),\n",
        "        final_theta=final_theta_torch,\n",
        "    )\n",
        "\n",
        "    # Optional: persist with slim logger keyed only by (library, N, D)\n",
        "    info = None\n",
        "    if save:\n",
        "        info = append_run_inplace_slim(\n",
        "            runlog,\n",
        "            library=f\"{library_name}:{backend_tag}\",\n",
        "            N=N,\n",
        "            D=D,\n",
        "            seed=seed,\n",
        "            outdir=outdir,\n",
        "            summary_csv=f\"{outdir}/summary.csv\",\n",
        "        )\n",
        "        print(f\"[append] Appended {len(runlog.exp_values)} iters starting from {info['start_iter']} (run_id={info['run_id']}).\")\n",
        "\n",
        "    return info, runlog\n"
      ],
      "metadata": {
        "id": "huBriW-mTkgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "from typing import Any, List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import quimb as qu\n",
        "import quimb.tensor as qtn\n",
        "\n",
        "# expects you already have:\n",
        "# - RunLog dataclass\n",
        "# - append_run_inplace_slim(library, N, D, outdir, summary_csv)\n",
        "# - create_hamiltonian(N, graph) -> list[(weight, mask)] with mask: List[bool] length N\n",
        "#   (or pass directly the same \"graph\" format you used elsewhere and call create_hamiltonian before)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# Helpers\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "def _build_ansatz_quimb(theta: np.ndarray, N: int, D: int) -> qtn.Circuit:\n",
        "    \"\"\"\n",
        "    theta: shape (D, 2N)\n",
        "    Returns a quimb Circuit with layers:\n",
        "      [ RX(j), RZ(j) for j in 0..N-1 ] + CNOT chain (j->j+1)\n",
        "    \"\"\"\n",
        "    c = qtn.Circuit(N)\n",
        "    for d in range(D):\n",
        "        # RX on all qubits\n",
        "        for j in range(N):\n",
        "            c.apply_gate(\"RX\", float(theta[d, j]), j)\n",
        "        # RZ on all qubits\n",
        "        for j in range(N):\n",
        "            c.apply_gate(\"RZ\", float(theta[d, N + j]), j)\n",
        "        # linear entangling CNOTs\n",
        "        for j in range(N - 1):\n",
        "            c.apply_gate(\"CNOT\", j, j + 1)\n",
        "        c.apply_gate(\"CNOT\", N-1,0)\n",
        "    return c\n",
        "\n",
        "def _psi_probs_from_circuit(circ: qtn.Circuit) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return |psi|^2 probabilities as a 1D array of length 2**N.\n",
        "    \"\"\"\n",
        "    # get the state as a TensorNetwork ket and densify\n",
        "    psi = circ.psi  # TN object\n",
        "    vec = psi.to_dense()  # complex ndarray shape (2**N,)\n",
        "    probs = (vec.real**2 + vec.imag**2).astype(np.float64)\n",
        "    return probs\n",
        "\n",
        "def _z_product_expectation_from_probs(probs: np.ndarray, N: int, z_idx: List[int]) -> float:\n",
        "    \"\"\"\n",
        "    E[Z_{z1} Z_{z2} ...] computed from computational basis probabilities.\n",
        "    sign = (-1)^{# of 1-bits among z_idx in basis state}\n",
        "    \"\"\"\n",
        "    if not z_idx:\n",
        "        return 1.0\n",
        "    # Precompute bit masks\n",
        "    mask = 0\n",
        "    for i in z_idx:\n",
        "        mask |= (1 << i)\n",
        "    exp_val = 0.0\n",
        "    for b, p in enumerate(probs):\n",
        "        # count ones among z_idx: popcount of (b & mask)\n",
        "        ones = (b & mask).bit_count()\n",
        "        sign = -1.0 if (ones % 2) else 1.0\n",
        "        exp_val += sign * p\n",
        "    return float(exp_val)\n",
        "\n",
        "def _energy_from_theta(theta: np.ndarray, N: int, D: int, hm_terms: List[tuple]) -> float:\n",
        "    \"\"\"\n",
        "    hm_terms: iterable of (weight, mask) where mask is List[bool] length N (Z on True sites).\n",
        "    Energy = sum_i -w_i * <Z^mask_i>\n",
        "    \"\"\"\n",
        "    circ = _build_ansatz_quimb(theta, N, D)\n",
        "    probs = _psi_probs_from_circuit(circ)\n",
        "    bitstrings = [format(i, f'0{N}b') for i in range(2**N)]\n",
        "    prob_dict = {b: float(val) for b, val in zip(bitstrings, probs.flatten())}\n",
        "    #print(prob_dict)\n",
        "    E = 0.0\n",
        "\n",
        "    for w, mask in hm_terms:\n",
        "        mask = mask[::-1]\n",
        "        z_idx = [i for i, m in enumerate(mask) if m]\n",
        "\n",
        "        #if z_idx:\n",
        "        E += float(w) * _z_product_expectation_from_probs(probs, N, z_idx)\n",
        "\n",
        "    return float(E)\n",
        "\n",
        "def _parameter_shift_grad(theta: np.ndarray, N: int, D: int, hm_terms: List[tuple]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Parameter-shift gradient for RX/RZ gates: shift ¬±œÄ/2.\n",
        "    Returns grad with same shape as theta.\n",
        "    \"\"\"\n",
        "    grad = np.zeros_like(theta, dtype=np.float64)\n",
        "    shift = np.pi / 2.0\n",
        "\n",
        "    # Loop over all parameters\n",
        "    for d in range(D):\n",
        "        for k in range(2 * N):\n",
        "            # + shift\n",
        "            th_plus = theta.copy()\n",
        "            th_plus[d, k] += shift\n",
        "            E_plus = _energy_from_theta(th_plus, N, D, hm_terms)\n",
        "            # - shift\n",
        "            th_minus = theta.copy()\n",
        "            th_minus[d, k] -= shift\n",
        "            E_minus = _energy_from_theta(th_minus, N, D, hm_terms)\n",
        "\n",
        "            grad[d, k] = 0.5 * (E_plus - E_minus)\n",
        "    return grad\n",
        "import numpy as np\n",
        "import quimb as qu\n",
        "\n",
        "def quimb_H_from_bool_terms(hm_terms, N=None):\n",
        "    \"\"\"\n",
        "    hm_terms: list[(weight: float, mask: tuple[bool,...])]\n",
        "      True -> Z, False -> I\n",
        "    N: number of qubits; inferred from first mask if None.\n",
        "    \"\"\"\n",
        "    if N is None:\n",
        "        N = len(hm_terms[0][1])\n",
        "    N = int(N)\n",
        "\n",
        "    I = qu.pauli('I')\n",
        "    Z = qu.pauli('Z')\n",
        "\n",
        "    H = np.zeros((2**N, 2**N), dtype=complex)\n",
        "\n",
        "    for w, mask in hm_terms:\n",
        "        # collect non-identity sites\n",
        "        inds = [i for i, b in enumerate(mask) if b]\n",
        "        if not inds:\n",
        "            H += w * np.eye(2**N, dtype=complex)\n",
        "            continue\n",
        "\n",
        "        # kron only the Zs, then place them at indices via ikron\n",
        "        term_local = Z\n",
        "        for _ in range(len(inds) - 1):\n",
        "            term_local = qu.kron(term_local, Z)\n",
        "\n",
        "        term_full = qu.ikron(term_local, dims=[2]*N, inds=inds)\n",
        "        H += w * term_full\n",
        "\n",
        "    return qu.qarray(H)\n",
        "\n",
        "def norm_fn(psi):\n",
        "    # we could always define this within the loss function, but separating it\n",
        "    # out can be clearer - it's also called before returning the optimized TN\n",
        "    nfact = (psi.H @ psi)**0.5\n",
        "    return psi.multiply(1 / nfact, spread_over='all')\n",
        "\n",
        "\n",
        "def loss_fn(psi, ham):\n",
        "    b, h, k = qtn.tensor_network_align(psi.H, ham, psi)\n",
        "    energy_tn = b | h | k\n",
        "    return energy_tn ^ ...\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# Main: same signature as your other backends\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "def benchmark_quimb_device(\n",
        "    graph,\n",
        "    theta,\n",
        "    D: int,\n",
        "    seed: int,\n",
        "    steps: int,\n",
        "    use_mps: bool,         # accepted for signature compatibility; not used in this baseline\n",
        "    device: str,           # \"cpu\" or \"cuda\" (quimb here runs on CPU; kept for signature symmetry)\n",
        "    lr: float = 0.1,\n",
        "    *,\n",
        "    library_name: str = \"quimb\",\n",
        "    save: bool = True,\n",
        "    outdir: str = \"bench_out_quimb\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Quimb benchmark with TensorCircuit-compatible signature.\n",
        "    Uses quimb.tensor.Circuit for the ansatz and parameter-shift gradients.\n",
        "    Returns (info_dict_or_None, RunLog).\n",
        "    \"\"\"\n",
        "    # infer N from edges: graph like [((u,v), w), ...]\n",
        "    N = max(max(u, v) for (u, v), _ in graph) + 1\n",
        "    print(f\"\\nüßµ Quimb | N={N} | backend={'MPS' if use_mps else 'TN/Circuit'} | device={device} | D={D} | steps={steps}\")\n",
        "\n",
        "    # Build Ising-like terms from your helper (same as your TensorCircuit code)\n",
        "    hm_terms = create_hamiltonian(N, graph)  # -> list of (weight, mask)\n",
        "    print(hm_terms)\n",
        "    # Œ∏ ‚àà R^{D √ó 2N}\n",
        "    # rng = np.random.default_rng()\n",
        "    # theta = rng.standard_normal((D, 2 * N)).astype(np.float64)\n",
        "        # Œ∏ ‚àà R^{D √ó 2N}\n",
        "    theta = theta[:D* 2 * N]  # shape: [8]\n",
        "\n",
        "    # Reshape to [2, 4]\n",
        "    theta = theta.detach().cpu().numpy().reshape(D, 2 * N).astype(np.float64)\n",
        "    #theta = np.random.rand(D, 2 * N).astype(np.float64)\n",
        "    exp_values: List[float] = []\n",
        "    best_results: List[Any] = []\n",
        "    iter_times: List[float] = []\n",
        "    circ = _build_ansatz_quimb(theta, N, D)\n",
        "    best_energy = float(\"inf\")\n",
        "    best_any: Any = None\n",
        "\n",
        "    ham = quimb_H_from_bool_terms(hm_terms, N )\n",
        "    tnopt = qtn.TNOptimizer(\n",
        "        # the tensor network we want to optimize\n",
        "        circ,\n",
        "        # the functions specfying the loss and normalization\n",
        "        loss_fn=loss_fn,\n",
        "        norm_fn=norm_fn,\n",
        "        # we specify constants so that the arguments can be converted\n",
        "        # to the  desired autodiff backend automatically\n",
        "        loss_constants={\"ham\": ham},\n",
        "        # the underlying algorithm to use for the optimization\n",
        "        # 'l-bfgs-b' is the default and often good for fast initial progress\n",
        "        optimizer=\"sdg\",\n",
        "        # which gradient computation backend to use\n",
        "        autodiff_backend=\"jax\",\n",
        "    )\n",
        "    # for step in range(steps):\n",
        "    #     t0 = time.time()\n",
        "\n",
        "    #     # energy and gradient via parameter shift\n",
        "    #     energy = _energy_from_theta(theta, N, D, hm_terms)\n",
        "    #     #grad = _parameter_shift_grad(theta, N, D, hm_terms)\n",
        "    #     grad =\n",
        "    #     theta = theta - lr * grad\n",
        "\n",
        "    #     dt = time.time() - t0\n",
        "    #     exp_values.append(float(energy))\n",
        "    #     iter_times.append(dt)\n",
        "    #     best_results.append(best_any)\n",
        "\n",
        "    #     if energy < best_energy:\n",
        "    #         best_energy = float(energy)\n",
        "    #         best_any = {\"step\": step, \"energy\": best_energy}\n",
        "\n",
        "    #     #print(f\"Step {step:2d}: E={float(energy):.6f} | t={dt:.3f}s\")\n",
        "\n",
        "    final_theta_torch = torch.from_numpy(theta.copy()).detach().clone()\n",
        "    runlog = RunLog(\n",
        "        exp_values=[float(v) for v in exp_values],\n",
        "        best_results=list(best_results),\n",
        "        iter_times=list(iter_times),\n",
        "        final_theta=final_theta_torch,\n",
        "    )\n",
        "\n",
        "    info = None\n",
        "    if save:\n",
        "        info = append_run_inplace_slim(\n",
        "            runlog,\n",
        "            library=f\"{library_name}:{'mps' if use_mps else 'tn'}\",\n",
        "            N=N,\n",
        "            D=D,\n",
        "            seed=seed,\n",
        "            outdir=outdir,\n",
        "            summary_csv=f\"{outdir}/summary.csv\",\n",
        "        )\n",
        "        print(f\"[append] Appended {len(runlog.exp_values)} iters starting from {info['start_iter']} (run_id={info['run_id']}).\")\n",
        "\n",
        "    return info, runlog\n"
      ],
      "metadata": {
        "id": "PDh8QDjEVXQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_N = 52\n",
        "graph_lookup = {(g['N'], g['graph_id']): g['G'] for g in graph_by_seed}\n",
        "for N in [24]:\n",
        "  for D in [3]:\n",
        "      for seed in [0]:\n",
        "        num_theta = 2*N*D\n",
        "        graph = graph_lookup[(N,seed)]\n",
        "        theta = theta_init_by_seed[seed][:num_theta]\n",
        "        steps = 10\n",
        "        # info, log = benchmark_tensorcircuit_tc_pytorch(\n",
        "        #     graph=graph,\n",
        "        #     D=D,\n",
        "        #     seed = seed,\n",
        "        #     steps=steps,\n",
        "        #     use_mps=False,\n",
        "        #     device=\"cuda\",\n",
        "        #     theta=theta,\n",
        "        #     lr=0.05,\n",
        "        #     library_name=\"tensorcircuit_full\",\n",
        "        #     save=True,\n",
        "        #     outdir=\"bench_out_comparison_cpu_real\"\n",
        "        # )\n",
        "        # info, log = benchmark_tensorcircuit_tc_pytorch(\n",
        "        #     graph=graph,\n",
        "        #     D=D,\n",
        "        #     seed = seed,\n",
        "        #     steps=steps,\n",
        "        #     use_mps=True,\n",
        "        #     device=\"cuda\",\n",
        "        #     theta=theta,\n",
        "        #     lr=0.05,\n",
        "        #     library_name=\"tensorcircuit_mps\",\n",
        "        #     save=True,\n",
        "        #     outdir=\"bench_out_comparison_cpu_real\"\n",
        "        # )\n",
        "\n",
        "        # info, log = benchmark_pennylane_device(\n",
        "        #     graph=graph,      # [((u,v), w), ...]\n",
        "        #     theta=theta,\n",
        "        #     D=D,\n",
        "        #     seed=seed,\n",
        "        #     steps=steps,\n",
        "        #     use_mps=True,     # accepted but ignored by PL\n",
        "        #     device=\"default.qubit\",    # or \"cpu\"\n",
        "        #     lr=0.05,\n",
        "        #     library_name=\"pennylane_default\",\n",
        "        #     save=True,\n",
        "        #     outdir=\"bench_out_comparison_cpu_real\"\n",
        "        # )\n",
        "        # info, log = benchmark_pennylane_device(\n",
        "        #     graph=graph,      # [((u,v), w), ...]\n",
        "        #     theta=theta,\n",
        "        #     D=D,\n",
        "        #     seed=seed,\n",
        "        #     steps=steps,\n",
        "        #     use_mps=True,     # accepted but ignored by PL\n",
        "        #     device=\"lightning.qubit\",    # or \"cpu\"\n",
        "        #     lr=0.05,\n",
        "        #     library_name=\"pennylane_lightning\",\n",
        "        #     save=True,\n",
        "        #     outdir=\"bench_out_comparison_cpu_real\"\n",
        "        # )\n",
        "        info, log = benchmark_qiskit_device(\n",
        "          graph=graph,      # [((u,v), w), ...]\\\n",
        "          theta = theta_init_by_seed[0],\n",
        "          D=D,\n",
        "          seed=seed,\n",
        "          steps=steps,\n",
        "          use_mps=True,     # accepted but ignored by PL\n",
        "          device=\"CPU\",    # or \"cpu\"\n",
        "          lr=0.05,\n",
        "          library_name=\"qiskit_mps\",\n",
        "          save=True,\n",
        "          outdir=\"bench_out_comparison_cpu_real\"\n",
        "        )\n",
        "        # info, log = benchmark_quimb_device(\n",
        "        #   graph=graph,      # [((u,v), w), ...]\\\n",
        "        #   theta = theta_init_by_seed[0],\n",
        "        #   D=D,\n",
        "        #   seed=seed,\n",
        "        #   steps=steps,\n",
        "        #   use_mps=True,     # accepted but ignored by PL\n",
        "        #   device=\"CPU\",    # or \"cpu\"\n",
        "        #   lr=0.05,\n",
        "        #   library_name=\"quimb\",\n",
        "        #   save=True,\n",
        "        #   outdir=\"bench_out_comparison_cpu_real\"\n",
        "        # )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "collapsed": true,
        "id": "zpHHtB1i0riz",
        "outputId": "6c21469f-83f5-4fd1-f350-2d81905db78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß Qiskit MPS | N=24 | Device=CPU | D=3 | steps=10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4067923880.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m#     outdir=\"bench_out_comparison_cpu_real\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         info, log = benchmark_qiskit_device(\n\u001b[0m\u001b[1;32m     64\u001b[0m           \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# [((u,v), w), ...]\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m           \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_init_by_seed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1974705120.py\u001b[0m in \u001b[0;36mbenchmark_qiskit_device\u001b[0;34m(graph, theta, D, seed, steps, use_mps, device, lr, library_name, save, outdir)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpectation_qiskit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mgrad\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mparameter_shift_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1974705120.py\u001b[0m in \u001b[0;36mparameter_shift_grad\u001b[0;34m(theta, N, D, obs, shift, use_mps, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtheta_minus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtheta_minus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mf_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpectation_qiskit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mf_minus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpectation_qiskit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_minus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf_plus\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf_minus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1974705120.py\u001b[0m in \u001b[0;36mexpectation_qiskit\u001b[0;34m(theta, N, D, obs, use_mps, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAerSimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"matrix_product_state\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_mps\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"statevector\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mqc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_statevector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0msv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_statevector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpectation_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_aer/jobs/utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJobError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job not submitted yet!. You have to .submit() first!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_aer/jobs/aerjob.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mcancelled\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires_submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_N = 52\n",
        "graph_lookup = {(g['N'], g['graph_id']): g['G'] for g in graph_by_seed}\n",
        "for N in [4,8,16]:\n",
        "  for D in [3]:\n",
        "      for seed in [1,2]:\n",
        "        num_theta = 2*N*D\n",
        "        graph = graph_lookup[(N,seed)]\n",
        "        theta = theta_init_by_seed[seed][:num_theta]\n",
        "        steps = 100\n",
        "        info, log = benchmark_tensorcircuit_tc_pytorch(\n",
        "            graph=graph,\n",
        "            D=D,\n",
        "            seed = seed,\n",
        "            steps=steps,\n",
        "            use_mps=False,\n",
        "            device=\"cuda\",\n",
        "            theta=theta,\n",
        "            lr=0.05,\n",
        "            library_name=\"tensorcircuit_full\",\n",
        "            save=True,\n",
        "            outdir=\"bench_out_comparison_cpu_real\"\n",
        "        )\n",
        "        info, log = benchmark_tensorcircuit_tc_pytorch(\n",
        "            graph=graph,\n",
        "            D=D,\n",
        "            seed = seed,\n",
        "            steps=steps,\n",
        "            use_mps=True,\n",
        "            device=\"cuda\",\n",
        "            theta=theta,\n",
        "            lr=0.05,\n",
        "            library_name=\"tensorcircuit_mps\",\n",
        "            save=True,\n",
        "            outdir=\"bench_out_comparison_cpu_real\"\n",
        "        )\n",
        "\n",
        "        info, log = benchmark_pennylane_device(\n",
        "            graph=graph,      # [((u,v), w), ...]\n",
        "            theta=theta,\n",
        "            D=D,\n",
        "            seed=seed,\n",
        "            steps=steps,\n",
        "            use_mps=True,     # accepted but ignored by PL\n",
        "            device=\"default.qubit\",    # or \"cpu\"\n",
        "            lr=0.05,\n",
        "            library_name=\"pennylane_default\",\n",
        "            save=True,\n",
        "            outdir=\"bench_out_comparison_cpu_real\"\n",
        "        )\n",
        "        info, log = benchmark_pennylane_device(\n",
        "            graph=graph,      # [((u,v), w), ...]\n",
        "            theta=theta,\n",
        "            D=D,\n",
        "            seed=seed,\n",
        "            steps=steps,\n",
        "            use_mps=True,     # accepted but ignored by PL\n",
        "            device=\"lightning.qubit\",    # or \"cpu\"\n",
        "            lr=0.05,\n",
        "            library_name=\"pennylane_lightning\",\n",
        "            save=True,\n",
        "            outdir=\"bench_out_comparison_cpu_real\"\n",
        "        )\n",
        "        info, log = benchmark_qiskit_device(\n",
        "          graph=graph,      # [((u,v), w), ...]\\\n",
        "          theta = theta_init_by_seed[0],\n",
        "          D=D,\n",
        "          seed=seed,\n",
        "          steps=steps,\n",
        "          use_mps=True,     # accepted but ignored by PL\n",
        "          device=\"CPU\",    # or \"cpu\"\n",
        "          lr=0.05,\n",
        "          library_name=\"qiskit_mps\",\n",
        "          save=True,\n",
        "          outdir=\"bench_out_comparison_cpu_real\"\n",
        "        )\n",
        "        info, log = benchmark_quimb_device(\n",
        "          graph=graph,      # [((u,v), w), ...]\\\n",
        "          theta = theta_init_by_seed[0],\n",
        "          D=D,\n",
        "          seed=seed,\n",
        "          steps=steps,\n",
        "          use_mps=True,     # accepted but ignored by PL\n",
        "          device=\"CPU\",    # or \"cpu\"\n",
        "          lr=0.05,\n",
        "          library_name=\"quimb\",\n",
        "          save=True,\n",
        "          outdir=\"bench_out_comparison_cpu_real\"\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "id": "8GoaxJbqHOaw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}