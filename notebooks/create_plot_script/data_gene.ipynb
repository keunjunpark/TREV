{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1938799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory of TRVQA to sys.path\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "from TRVQA.measure.enums import MeasureMethod\n",
    "from TRVQA.optimization.gradients.vanilla_parameter_shift import vanilla_parameter_shift\n",
    "from TRVQA.optimization.optimization import minimize, minimize_custom\n",
    "from TRVQA.utils.maxcut import gengraph, create_hamiltonian, make_hamiltonian\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from qiskit.circuit.library import QAOAAnsatz\n",
    "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from TRVQA.circuit import Circuit\n",
    "\n",
    "def compute_maxcut_value(bitstring, graph):\n",
    "    \"\"\"Computes the MaxCut value for a given bitstring solution.\"\"\"\n",
    "    cut_value = sum(w for (u,v), w in graph if bitstring[u] != bitstring[v])\n",
    "    return cut_value\n",
    "\n",
    "# for s in best_value:\n",
    "#     print(compute_maxcut_value(s, g))\n",
    "\n",
    "from pyparsing import Optional\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp\n",
    "from TRVQA.optimization.optimization import minimize, minimize_custom\n",
    "# TRVQA imports\n",
    "\n",
    "from TRVQA.circuit import Circuit\n",
    "from TRVQA.hamiltonian.hamiltonian import Hamiltonian\n",
    "from TRVQA.measure.enums import MeasureMethod\n",
    "torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "import torch\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp\n",
    "import torch\n",
    "\n",
    "from TRVQA.measure.enums import MeasureMethod\n",
    "from TRVQA.optimization.optimization import minimize\n",
    "from TRVQA.utils.maxcut import gengraph, create_hamiltonian,make_hamiltonian\n",
    "from TRVQA.hamiltonian.hamiltonian import Hamiltonian\n",
    "import numpy as np\n",
    "import torch\n",
    "from TRVQA.circuit import Circuit\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913334f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total graphs: 30  (expected 30)\n",
      "Total (graph, depth) pairs: 30  (expected 30)\n",
      "N=150 gid=0  depth=1  seed=171207760\n",
      "N=150 gid=1  depth=1  seed=170960767\n",
      "N=150 gid=2  depth=1  seed=171833870\n",
      "N=150 gid=3  depth=1  seed=171576797\n",
      "N=150 gid=4  depth=1  seed=170344684\n",
      "N=150 gid=5  depth=1  seed=170105788\n",
      "N=150 gid=6  depth=1  seed=170438474\n",
      "N=150 gid=7  depth=1  seed=169206297\n",
      "N=150 gid=8  depth=1  seed=168965416\n",
      "N=150 gid=9  depth=1  seed=169822457\n",
      "N=500 gid=0  depth=1  seed=528752828\n",
      "N=500 gid=1  depth=1  seed=528542613\n",
      "N=500 gid=2  depth=1  seed=529381092\n",
      "N=500 gid=3  depth=1  seed=529154359\n",
      "N=500 gid=4  depth=1  seed=529992710\n",
      "N=500 gid=5  depth=1  seed=529782609\n",
      "N=500 gid=6  depth=1  seed=530113441\n",
      "N=500 gid=7  depth=1  seed=530951924\n",
      "N=500 gid=8  depth=1  seed=530741698\n",
      "N=500 gid=9  depth=1  seed=531563550\n",
      "N=1000 gid=0  depth=1  seed=948511350\n",
      "N=1000 gid=1  depth=1  seed=948824409\n",
      "N=1000 gid=2  depth=1  seed=947958826\n",
      "N=1000 gid=3  depth=1  seed=948388860\n",
      "N=1000 gid=4  depth=1  seed=949620426\n",
      "N=1000 gid=5  depth=1  seed=949933469\n",
      "N=1000 gid=6  depth=1  seed=949346668\n",
      "N=1000 gid=7  depth=1  seed=950578239\n",
      "N=1000 gid=8  depth=1  seed=951024399\n",
      "N=1000 gid=9  depth=1  seed=950142673\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# --- Helper: deterministic seeding for reproducibility ---\n",
    "def _seed_everywhere(seed: int):\n",
    "    random.seed(seed)\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- Robust graph generation with retries & deterministic seeds ---\n",
    "def create_graphs_per_n(\n",
    "    Ns,\n",
    "    per_n: int = 10,\n",
    "    max_retries: int = 100,\n",
    "    base_seed: int = 12345,\n",
    "    gengraph_fn=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a list of dicts:\n",
    "      {'N': int, 'graph_id': int, 'seed': int, 'G': networkx.Graph}\n",
    "    \"\"\"\n",
    "    if gengraph_fn is None:\n",
    "        # Fall back to a global gengraph if it's already defined in your notebook\n",
    "        try:\n",
    "            gengraph_fn = globals()['gengraph']\n",
    "        except KeyError:\n",
    "            raise RuntimeError(\"Provide gengraph_fn or define a global `gengraph(N, seed=None)`.\")\n",
    "\n",
    "    runs = []\n",
    "    for N in Ns:\n",
    "        for gid in range(per_n):\n",
    "            # Stable seed per (N, graph_id)\n",
    "            base = (base_seed * 1_000_003) ^ (N * 9_73_733) ^ (gid * 31_4159)\n",
    "            for attempt in range(max_retries):\n",
    "                # Jitter the seed per attempt for robustness but remain deterministic\n",
    "                seed = (base + attempt) & 0x7FFFFFFF\n",
    "                _seed_everywhere(seed)\n",
    "                try:\n",
    "                    # Prefer gengraph_fn(N, seed=seed) if supported; else call gengraph_fn(N)\n",
    "                    try:\n",
    "                        G = gengraph_fn(N, seed=seed)\n",
    "                    except TypeError:\n",
    "                        G = gengraph_fn(N)\n",
    "                    runs.append({'N': N, 'graph_id': gid, 'seed': seed, 'G': G})\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        print(f\"[FAIL] N={N} gid={gid}: {e}\")\n",
    "                    # else retry with next seed\n",
    "    return runs\n",
    "\n",
    "# --- Build the experimental grid over depths (same depth set for all N) ---\n",
    "def build_experiment_grid(graph_runs, depths):\n",
    "    \"\"\"\n",
    "    graph_runs: output of create_graphs_per_n(...)\n",
    "    depths: iterable of circuit depths (same for all N)\n",
    "    Returns list of dicts:\n",
    "      {'N', 'graph_id', 'seed', 'depth', 'G'}\n",
    "    \"\"\"\n",
    "    grid = []\n",
    "    for r in graph_runs:\n",
    "        for d in depths:\n",
    "            grid.append({**r, 'depth': d})\n",
    "    return grid\n",
    "\n",
    "# ------------------ Example usage ------------------\n",
    "N_list = [150, 500, 1000]  # your Ns\n",
    "per_n = 10                                     # 10 graphs per N\n",
    "depths = [1]                   # SAME depth set used for every N\n",
    "\n",
    "graph_runs = create_graphs_per_n(\n",
    "    Ns=N_list,\n",
    "    per_n=per_n,\n",
    "    max_retries=100,\n",
    "    base_seed=42,          # change if you want a different reproducible suite\n",
    "    gengraph_fn=gengraph,  # or omit if gengraph is global\n",
    ")\n",
    "\n",
    "exp_grid = build_experiment_grid(graph_runs, depths)\n",
    "\n",
    "print(f\"Total graphs: {len(graph_runs)}  (expected {len(N_list)*per_n})\")\n",
    "print(f\"Total (graph, depth) pairs: {len(exp_grid)}  (expected {len(graph_runs)*len(depths)})\")\n",
    "# Optional: quick peek at the first few items\n",
    "for row in exp_grid:\n",
    "    print(f\"N={row['N']:<3} gid={row['graph_id']:<2} depth={row['depth']:<2} seed={row['seed']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efd5a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 150, 'graph_id': 0, 'seed': 171207760, 'G': [((0, 41), 1), ((0, 73), 6), ((0, 7), 1), ((1, 57), 10), ((1, 42), 6), ((1, 86), 4), ((2, 29), 3), ((2, 129), 10), ((2, 10), 6), ((3, 4), 7), ((3, 84), 2), ((3, 128), 1), ((4, 121), 5), ((4, 89), 3), ((5, 119), 3), ((5, 137), 5), ((5, 18), 5), ((6, 103), 7), ((6, 87), 8), ((6, 70), 5), ((7, 112), 4), ((7, 54), 7), ((8, 84), 9), ((8, 83), 8), ((8, 21), 2), ((9, 63), 4), ((9, 110), 6), ((9, 35), 2), ((10, 55), 10), ((10, 78), 10), ((11, 65), 9), ((11, 24), 1), ((11, 46), 7), ((12, 91), 5), ((12, 115), 1), ((12, 80), 1), ((13, 96), 6), ((13, 111), 6), ((13, 14), 8), ((14, 78), 2), ((14, 84), 7), ((15, 52), 7), ((15, 105), 2), ((15, 56), 10), ((16, 106), 7), ((16, 76), 8), ((16, 111), 3), ((17, 22), 9), ((17, 40), 5), ((17, 68), 3), ((18, 79), 4), ((18, 105), 2), ((19, 50), 8), ((19, 122), 7), ((19, 35), 1), ((20, 119), 4), ((20, 128), 9), ((20, 29), 7), ((21, 73), 3), ((21, 58), 2), ((22, 64), 4), ((22, 135), 9), ((23, 48), 7), ((23, 50), 8), ((23, 40), 4), ((24, 28), 9), ((24, 27), 7), ((25, 83), 3), ((25, 32), 4), ((25, 145), 8), ((26, 67), 4), ((26, 36), 5), ((26, 44), 5), ((27, 126), 4), ((27, 91), 1), ((28, 128), 8), ((28, 97), 8), ((29, 39), 3), ((30, 114), 4), ((30, 92), 3), ((30, 119), 1), ((31, 96), 7), ((31, 113), 8), ((31, 121), 9), ((32, 130), 2), ((32, 142), 4), ((33, 70), 5), ((33, 72), 10), ((33, 135), 1), ((34, 55), 4), ((34, 110), 7), ((34, 90), 5), ((35, 137), 7), ((36, 121), 9), ((36, 39), 8), ((37, 70), 5), ((37, 111), 7), ((37, 54), 4), ((38, 107), 7), ((38, 104), 6), ((38, 115), 7), ((39, 148), 3), ((40, 125), 9), ((41, 44), 8), ((41, 86), 5), ((42, 98), 1), ((42, 51), 8), ((43, 127), 1), ((43, 47), 8), ((43, 101), 8), ((44, 143), 3), ((45, 136), 8), ((45, 137), 10), ((45, 139), 8), ((46, 66), 6), ((46, 77), 1), ((47, 95), 8), ((47, 58), 2), ((48, 80), 4), ((48, 73), 5), ((49, 113), 4), ((49, 79), 4), ((49, 106), 5), ((50, 131), 8), ((51, 82), 3), ((51, 81), 3), ((52, 71), 7), ((52, 66), 7), ((53, 61), 10), ((53, 102), 8), ((53, 54), 6), ((55, 81), 5), ((56, 136), 5), ((56, 115), 1), ((57, 88), 10), ((57, 129), 9), ((58, 103), 4), ((59, 105), 10), ((59, 95), 3), ((59, 62), 2), ((60, 61), 6), ((60, 126), 8), ((60, 65), 6), ((61, 76), 7), ((62, 124), 7), ((62, 104), 8), ((63, 75), 10), ((63, 78), 4), ((64, 114), 5), ((64, 80), 2), ((65, 85), 4), ((66, 141), 4), ((67, 83), 6), ((67, 86), 6), ((68, 81), 6), ((68, 133), 4), ((69, 107), 5), ((69, 147), 2), ((69, 141), 5), ((71, 113), 6), ((71, 123), 10), ((72, 106), 8), ((72, 125), 1), ((74, 103), 4), ((74, 102), 3), ((74, 146), 9), ((75, 138), 8), ((75, 133), 8), ((76, 125), 3), ((77, 124), 5), ((77, 98), 4), ((79, 118), 10), ((82, 116), 4), ((82, 110), 6), ((85, 109), 4), ((85, 127), 7), ((87, 134), 7), ((87, 143), 9), ((88, 131), 8), ((88, 95), 6), ((89, 133), 3), ((89, 90), 2), ((90, 122), 4), ((91, 101), 9), ((92, 145), 8), ((92, 149), 9), ((93, 120), 10), ((93, 94), 6), ((93, 99), 10), ((94, 145), 4), ((94, 134), 5), ((96, 140), 1), ((97, 99), 1), ((97, 140), 3), ((98, 146), 1), ((99, 140), 2), ((100, 135), 9), ((100, 104), 2), ((100, 124), 4), ((101, 109), 9), ((102, 147), 1), ((107, 117), 4), ((108, 129), 10), ((108, 114), 2), ((108, 134), 5), ((109, 123), 2), ((112, 147), 4), ((112, 136), 9), ((116, 148), 9), ((116, 144), 8), ((117, 122), 9), ((117, 126), 9), ((118, 123), 3), ((118, 131), 2), ((120, 141), 4), ((120, 130), 5), ((127, 144), 6), ((130, 142), 8), ((132, 144), 1), ((132, 139), 3), ((132, 149), 3), ((138, 143), 4), ((138, 148), 9), ((139, 146), 2), ((142, 149), 3)], 'depth': 1}\n"
     ]
    }
   ],
   "source": [
    "print(exp_grid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91516463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 entries to experiment_grid_high_N.json ✅\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Your exp_grid looks like:\n",
    "# [{'N': 4, 'graph_id': 0, 'seed': 45854826, 'G': [((0, 3), 3), ...], 'depth': 1}, ...]\n",
    "\n",
    "# STEP 1: Convert tuple keys to lists (JSON doesn’t support tuple)\n",
    "def make_json_serializable(obj):\n",
    "    if isinstance(obj, tuple):\n",
    "        return list(obj)\n",
    "    if isinstance(obj, list):\n",
    "        return [make_json_serializable(x) for x in obj]\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: make_json_serializable(v) for k, v in obj.items()}\n",
    "    return obj\n",
    "\n",
    "json_ready = [make_json_serializable(entry) for entry in exp_grid]\n",
    "\n",
    "# STEP 2: Save to JSON file\n",
    "with open(\"experiment_grid_high_N.json\", \"w\") as f:\n",
    "    json.dump(json_ready, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(json_ready)} entries to experiment_grid_high_N.json ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b26a9cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 4, 'graph_id': 0, 'seed': 45854826, 'G': [((0, 3), 3), ((0, 2), 1), ((0, 1), 5), ((1, 2), 7), ((1, 3), 8), ((2, 3), 8)], 'depth': 1}\n"
     ]
    }
   ],
   "source": [
    "with open(\"experiment_grid.json\", \"r\") as f:\n",
    "    loaded = json.load(f)\n",
    "\n",
    "# Convert lists back to tuples if you want\n",
    "def convert_lists_to_tuples(obj):\n",
    "    if isinstance(obj, list):\n",
    "        # Check if list looks like an edge [(0,1), w]\n",
    "        if len(obj) == 2 and isinstance(obj[0], list) and isinstance(obj[1], (int, float)):\n",
    "            return (tuple(obj[0]), obj[1])\n",
    "        else:\n",
    "            return [convert_lists_to_tuples(x) for x in obj]\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_lists_to_tuples(v) for k, v in obj.items()}\n",
    "    return obj\n",
    "\n",
    "exp_grid_loaded = [convert_lists_to_tuples(entry) for entry in loaded]\n",
    "\n",
    "print(exp_grid_loaded[0])  # should match your original structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08b05b",
   "metadata": {},
   "source": [
    "TSP Graph GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cdaa037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_optimization.applications import Tsp\n",
    "import networkx as nx\n",
    "def gengraph_tsp(N, seed=None):\n",
    "    n = int(np.sqrt(N))\n",
    "    tsp = Tsp.create_random_instance(n, seed=seed)\n",
    "    qp = tsp.to_quadratic_program()\n",
    "\n",
    "    val = nx.to_dict_of_dicts(tsp.graph)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c335218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total graphs: 90  (expected 90)\n",
      "Total (graph, depth) pairs: 90  (expected 90)\n",
      "{0: {1: {'weight': np.float64(38.0)}, 2: {'weight': np.float64(13.0)}, 3: {'weight': np.float64(24.0)}, 4: {'weight': np.float64(73.0)}, 5: {'weight': np.float64(47.0)}, 6: {'weight': np.float64(32.0)}}, 1: {0: {'weight': np.float64(38.0)}, 2: {'weight': np.float64(50.0)}, 3: {'weight': np.float64(28.0)}, 4: {'weight': np.float64(42.0)}, 5: {'weight': np.float64(57.0)}, 6: {'weight': np.float64(6.0)}}, 2: {0: {'weight': np.float64(13.0)}, 1: {'weight': np.float64(50.0)}, 3: {'weight': np.float64(32.0)}, 4: {'weight': np.float64(82.0)}, 5: {'weight': np.float64(53.0)}, 6: {'weight': np.float64(44.0)}}, 3: {0: {'weight': np.float64(24.0)}, 1: {'weight': np.float64(28.0)}, 2: {'weight': np.float64(32.0)}, 4: {'weight': np.float64(51.0)}, 5: {'weight': np.float64(65.0)}, 6: {'weight': np.float64(22.0)}}, 4: {0: {'weight': np.float64(73.0)}, 1: {'weight': np.float64(42.0)}, 2: {'weight': np.float64(82.0)}, 3: {'weight': np.float64(51.0)}, 5: {'weight': np.float64(99.0)}, 6: {'weight': np.float64(45.0)}}, 5: {0: {'weight': np.float64(47.0)}, 1: {'weight': np.float64(57.0)}, 2: {'weight': np.float64(53.0)}, 3: {'weight': np.float64(65.0)}, 4: {'weight': np.float64(99.0)}, 6: {'weight': np.float64(55.0)}}, 6: {0: {'weight': np.float64(32.0)}, 1: {'weight': np.float64(6.0)}, 2: {'weight': np.float64(44.0)}, 3: {'weight': np.float64(22.0)}, 4: {'weight': np.float64(45.0)}, 5: {'weight': np.float64(55.0)}}}\n",
      "None\n",
      "minimize 38*x_0_0*x_1_1 + 38*x_0_0*x_1_6 + 13*x_0_0*x_2_1 + 13*x_0_0*x_2_6 + 24*x_0_0*x_3_1 + 24*x_0_0*x_3_6 + 73*x_0_0*x_4_1 + 73*x_0_0*x_4_6 + 47*x_0_0*x_5_1 + 47*x_0_0*x_5_6 + 32*x_0_0*x_6_1 + 32*x_0_0*x_6_6 + 38*x_0_1*x_1_0 + 38*x_0_1*x_1_2 + 13*x_0_1*x_2_0 + 13*x_0_1*x_2_2 + 24*x_0_1*x_3_0 + 24*x_0_1*x_3_2 + 73*x_0_1*x_4_0 + 73*x_0_1*x_4_2 + 47*x_0_1*x_5_0 + 47*x_0_1*x_5_2 + 32*x_0_1*x_6_0 + 32*x_0_1*x_6_2 + 38*x_0_2*x_1_1 + 38*x_0_2*x_1_3 + 13*x_0_2*x_2_1 + 13*x_0_2*x_2_3 + 24*x_0_2*x_3_1 + 24*x_0_2*x_3_3 + 73*x_0_2*x_4_1 + 73*x_0_2*x_4_3 + 47*x_0_2*x_5_1 + 47*x_0_2*x_5_3 + 32*x_0_2*x_6_1 + 32*x_0_2*x_6_3 + 38*x_0_3*x_1_2 + 38*x_0_3*x_1_4 + 13*x_0_3*x_2_2 + 13*x_0_3*x_2_4 + 24*x_0_3*x_3_2 + 24*x_0_3*x_3_4 + 73*x_0_3*x_4_2 + 73*x_0_3*x_4_4 + 47*x_0_3*x_5_2 + 47*x_0_3*x_5_4 + 32*x_0_3*x_6_2 + 32*x_0_3*x_6_4 + 38*x_0_4*x_1_3 + 38*x_0_4*x_1_5 + 13*x_0_4*x_2_3 + 13*x_0_4*x_2_5 + 24*x_0_4*x_3_3 + 24*x_0_4*x_3_5 + 73*x_0_4*x_4_3 + 73*x_0_4*x_4_5 + 47*x_0_4*x_5_3 + 47*x_0_4*x_5_5 + 32*x_0_4*x_6_3 + 32*x_0_4*x_6_5 + 38*x_0_5*x_1_4 + 38*x_0_5*x_1_6 + 13*x_0_5*x_2_4 + 13*x_0_5*x_2_6 + 24*x_0_5*x_3_4 + 24*x_0_5*x_3_6 + 73*x_0_5*x_4_4 + 73*x_0_5*x_4_6 + 47*x_0_5*x_5_4 + 47*x_0_5*x_5_6 + 32*x_0_5*x_6_4 + 32*x_0_5*x_6_6 + 38*x_0_6*x_1_0 + 38*x_0_6*x_1_5 + 13*x_0_6*x_2_0 + 13*x_0_6*x_2_5 + 24*x_0_6*x_3_0 + 24*x_0_6*x_3_5 + 73*x_0_6*x_4_0 + 73*x_0_6*x_4_5 + 47*x_0_6*x_5_0 + 47*x_0_6*x_5_5 + 32*x_0_6*x_6_0 + 32*x_0_6*x_6_5 + 50*x_1_0*x_2_1 + 50*x_1_0*x_2_6 + 28*x_1_0*x_3_1 + 28*x_1_0*x_3_6 + 42*x_1_0*x_4_1 + 42*x_1_0*x_4_6 + 57*x_1_0*x_5_1 + 57*x_1_0*x_5_6 + 6*x_1_0*x_6_1 + 6*x_1_0*x_6_6 + 50*x_1_1*x_2_0 + 50*x_1_1*x_2_2 + 28*x_1_1*x_3_0 + 28*x_1_1*x_3_2 + 42*x_1_1*x_4_0 + 42*x_1_1*x_4_2 + 57*x_1_1*x_5_0 + 57*x_1_1*x_5_2 + 6*x_1_1*x_6_0 + 6*x_1_1*x_6_2 + 50*x_1_2*x_2_1 + 50*x_1_2*x_2_3 + 28*x_1_2*x_3_1 + 28*x_1_2*x_3_3 + 42*x_1_2*x_4_1 + 42*x_1_2*x_4_3 + 57*x_1_2*x_5_1 + 57*x_1_2*x_5_3 + 6*x_1_2*x_6_1 + 6*x_1_2*x_6_3 + 50*x_1_3*x_2_2 + 50*x_1_3*x_2_4 + 28*x_1_3*x_3_2 + 28*x_1_3*x_3_4 + 42*x_1_3*x_4_2 + 42*x_1_3*x_4_4 + 57*x_1_3*x_5_2 + 57*x_1_3*x_5_4 + 6*x_1_3*x_6_2 + 6*x_1_3*x_6_4 + 50*x_1_4*x_2_3 + 50*x_1_4*x_2_5 + 28*x_1_4*x_3_3 + 28*x_1_4*x_3_5 + 42*x_1_4*x_4_3 + 42*x_1_4*x_4_5 + 57*x_1_4*x_5_3 + 57*x_1_4*x_5_5 + 6*x_1_4*x_6_3 + 6*x_1_4*x_6_5 + 50*x_1_5*x_2_4 + 50*x_1_5*x_2_6 + 28*x_1_5*x_3_4 + 28*x_1_5*x_3_6 + 42*x_1_5*x_4_4 + 42*x_1_5*x_4_6 + 57*x_1_5*x_5_4 + 57*x_1_5*x_5_6 + 6*x_1_5*x_6_4 + 6*x_1_5*x_6_6 + 50*x_1_6*x_2_0 + 50*x_1_6*x_2_5 + 28*x_1_6*x_3_0 + 28*x_1_6*x_3_5 + 42*x_1_6*x_4_0 + 42*x_1_6*x_4_5 + 57*x_1_6*x_5_0 + 57*x_1_6*x_5_5 + 6*x_1_6*x_6_0 + 6*x_1_6*x_6_5 + 32*x_2_0*x_3_1 + 32*x_2_0*x_3_6 + 82*x_2_0*x_4_1 + 82*x_2_0*x_4_6 + 53*x_2_0*x_5_1 + 53*x_2_0*x_5_6 + 44*x_2_0*x_6_1 + 44*x_2_0*x_6_6 + 32*x_2_1*x_3_0 + 32*x_2_1*x_3_2 + 82*x_2_1*x_4_0 + 82*x_2_1*x_4_2 + 53*x_2_1*x_5_0 + 53*x_2_1*x_5_2 + 44*x_2_1*x_6_0 + 44*x_2_1*x_6_2 + 32*x_2_2*x_3_1 + 32*x_2_2*x_3_3 + 82*x_2_2*x_4_1 + 82*x_2_2*x_4_3 + 53*x_2_2*x_5_1 + 53*x_2_2*x_5_3 + 44*x_2_2*x_6_1 + 44*x_2_2*x_6_3 + 32*x_2_3*x_3_2 + 32*x_2_3*x_3_4 + 82*x_2_3*x_4_2 + 82*x_2_3*x_4_4 + 53*x_2_3*x_5_2 + 53*x_2_3*x_5_4 + 44*x_2_3*x_6_2 + 44*x_2_3*x_6_4 + 32*x_2_4*x_3_3 + 32*x_2_4*x_3_5 + 82*x_2_4*x_4_3 + 82*x_2_4*x_4_5 + 53*x_2_4*x_5_3 + 53*x_2_4*x_5_5 + 44*x_2_4*x_6_3 + 44*x_2_4*x_6_5 + 32*x_2_5*x_3_4 + 32*x_2_5*x_3_6 + 82*x_2_5*x_4_4 + 82*x_2_5*x_4_6 + 53*x_2_5*x_5_4 + 53*x_2_5*x_5_6 + 44*x_2_5*x_6_4 + 44*x_2_5*x_6_6 + 32*x_2_6*x_3_0 + 32*x_2_6*x_3_5 + 82*x_2_6*x_4_0 + 82*x_2_6*x_4_5 + 53*x_2_6*x_5_0 + 53*x_2_6*x_5_5 + 44*x_2_6*x_6_0 + 44*x_2_6*x_6_5 + 51*x_3_0*x_4_1 + 51*x_3_0*x_4_6 + 65*x_3_0*x_5_1 + 65*x_3_0*x_5_6 + 22*x_3_0*x_6_1 + 22*x_3_0*x_6_6 + 51*x_3_1*x_4_0 + 51*x_3_1*x_4_2 + 65*x_3_1*x_5_0 + 65*x_3_1*x_5_2 + 22*x_3_1*x_6_0 + 22*x_3_1*x_6_2 + 51*x_3_2*x_4_1 + 51*x_3_2*x_4_3 + 65*x_3_2*x_5_1 + 65*x_3_2*x_5_3 + 22*x_3_2*x_6_1 + 22*x_3_2*x_6_3 + 51*x_3_3*x_4_2 + 51*x_3_3*x_4_4 + 65*x_3_3*x_5_2 + 65*x_3_3*x_5_4 + 22*x_3_3*x_6_2 + 22*x_3_3*x_6_4 + 51*x_3_4*x_4_3 + 51*x_3_4*x_4_5 + 65*x_3_4*x_5_3 + 65*x_3_4*x_5_5 + 22*x_3_4*x_6_3 + 22*x_3_4*x_6_5 + 51*x_3_5*x_4_4 + 51*x_3_5*x_4_6 + 65*x_3_5*x_5_4 + 65*x_3_5*x_5_6 + 22*x_3_5*x_6_4 + 22*x_3_5*x_6_6 + 51*x_3_6*x_4_0 + 51*x_3_6*x_4_5 + 65*x_3_6*x_5_0 + 65*x_3_6*x_5_5 + 22*x_3_6*x_6_0 + 22*x_3_6*x_6_5 + 99*x_4_0*x_5_1 + 99*x_4_0*x_5_6 + 45*x_4_0*x_6_1 + 45*x_4_0*x_6_6 + 99*x_4_1*x_5_0 + 99*x_4_1*x_5_2 + 45*x_4_1*x_6_0 + 45*x_4_1*x_6_2 + 99*x_4_2*x_5_1 + 99*x_4_2*x_5_3 + 45*x_4_2*x_6_1 + 45*x_4_2*x_6_3 + 99*x_4_3*x_5_2 + 99*x_4_3*x_5_4 + 45*x_4_3*x_6_2 + 45*x_4_3*x_6_4 + 99*x_4_4*x_5_3 + 99*x_4_4*x_5_5 + 45*x_4_4*x_6_3 + 45*x_4_4*x_6_5 + 99*x_4_5*x_5_4 + 99*x_4_5*x_5_6 + 45*x_4_5*x_6_4 + 45*x_4_5*x_6_6 + 99*x_4_6*x_5_0 + 99*x_4_6*x_5_5 + 45*x_4_6*x_6_0 + 45*x_4_6*x_6_5 + 55*x_5_0*x_6_1 + 55*x_5_0*x_6_6 + 55*x_5_1*x_6_0 + 55*x_5_1*x_6_2 + 55*x_5_2*x_6_1 + 55*x_5_2*x_6_3 + 55*x_5_3*x_6_2 + 55*x_5_3*x_6_4 + 55*x_5_4*x_6_3 + 55*x_5_4*x_6_5 + 55*x_5_5*x_6_4 + 55*x_5_5*x_6_6 + 55*x_5_6*x_6_0 + 55*x_5_6*x_6_5 (49 variables, 14 constraints, 'TSP')\n"
     ]
    }
   ],
   "source": [
    "N_list_tsp = [4, 9, 16, 25, 36, 49, 64, 81, 100]  # your Ns\n",
    "per_n = 10                                     # 10 graphs per N\n",
    "depths = [1]                   # SAME depth set used for every N\n",
    "graph_runs_tsp = create_graphs_per_n(\n",
    "    Ns=N_list_tsp,\n",
    "    per_n=10,\n",
    "    max_retries=100,\n",
    "    base_seed=42,          # change if you want a different reproducible suite\n",
    "    gengraph_fn=gengraph_tsp,  # or omit if gengraph is global\n",
    ")\n",
    "\n",
    "\n",
    "exp_grid_tsp = build_experiment_grid(graph_runs_tsp, depths)\n",
    "\n",
    "print(f\"Total graphs: {len(graph_runs_tsp)}  (expected {len(N_list_tsp)*per_n})\")\n",
    "print(f\"Total (graph, depth) pairs: {len(exp_grid_tsp)}  (expected {len(graph_runs_tsp)*len(depths)})\")\n",
    "# Optional: quick peek at the first few items\n",
    "# for row in exp_grid:\n",
    "#     print(f\"N={row['N']:<3} gid={row['graph_id']:<2} depth={row['depth']:<2} seed={row['seed']}\")\n",
    "\n",
    "print(print(exp_grid_tsp[50]['G']))\n",
    "\n",
    "print(Tsp(exp_grid_tsp[50]['G']).to_quadratic_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25a7885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 90 entries to experiment_grid_tsp.json ✅\n"
     ]
    }
   ],
   "source": [
    "json_ready_tsp = [make_json_serializable(entry) for entry in exp_grid_tsp]\n",
    "\n",
    "# STEP 2: Save to JSON file\n",
    "with open(\"experiment_grid_tsp.json\", \"w\") as f:\n",
    "    json.dump(json_ready_tsp, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(exp_grid_tsp)} entries to experiment_grid_tsp.json ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53559e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimize 38*x_0_0*x_1_1 + 38*x_0_0*x_1_6 + 13*x_0_0*x_2_1 + 13*x_0_0*x_2_6 + 24*x_0_0*x_3_1 + 24*x_0_0*x_3_6 + 73*x_0_0*x_4_1 + 73*x_0_0*x_4_6 + 47*x_0_0*x_5_1 + 47*x_0_0*x_5_6 + 32*x_0_0*x_6_1 + 32*x_0_0*x_6_6 + 38*x_0_1*x_1_0 + 38*x_0_1*x_1_2 + 13*x_0_1*x_2_0 + 13*x_0_1*x_2_2 + 24*x_0_1*x_3_0 + 24*x_0_1*x_3_2 + 73*x_0_1*x_4_0 + 73*x_0_1*x_4_2 + 47*x_0_1*x_5_0 + 47*x_0_1*x_5_2 + 32*x_0_1*x_6_0 + 32*x_0_1*x_6_2 + 38*x_0_2*x_1_1 + 38*x_0_2*x_1_3 + 13*x_0_2*x_2_1 + 13*x_0_2*x_2_3 + 24*x_0_2*x_3_1 + 24*x_0_2*x_3_3 + 73*x_0_2*x_4_1 + 73*x_0_2*x_4_3 + 47*x_0_2*x_5_1 + 47*x_0_2*x_5_3 + 32*x_0_2*x_6_1 + 32*x_0_2*x_6_3 + 38*x_0_3*x_1_2 + 38*x_0_3*x_1_4 + 13*x_0_3*x_2_2 + 13*x_0_3*x_2_4 + 24*x_0_3*x_3_2 + 24*x_0_3*x_3_4 + 73*x_0_3*x_4_2 + 73*x_0_3*x_4_4 + 47*x_0_3*x_5_2 + 47*x_0_3*x_5_4 + 32*x_0_3*x_6_2 + 32*x_0_3*x_6_4 + 38*x_0_4*x_1_3 + 38*x_0_4*x_1_5 + 13*x_0_4*x_2_3 + 13*x_0_4*x_2_5 + 24*x_0_4*x_3_3 + 24*x_0_4*x_3_5 + 73*x_0_4*x_4_3 + 73*x_0_4*x_4_5 + 47*x_0_4*x_5_3 + 47*x_0_4*x_5_5 + 32*x_0_4*x_6_3 + 32*x_0_4*x_6_5 + 38*x_0_5*x_1_4 + 38*x_0_5*x_1_6 + 13*x_0_5*x_2_4 + 13*x_0_5*x_2_6 + 24*x_0_5*x_3_4 + 24*x_0_5*x_3_6 + 73*x_0_5*x_4_4 + 73*x_0_5*x_4_6 + 47*x_0_5*x_5_4 + 47*x_0_5*x_5_6 + 32*x_0_5*x_6_4 + 32*x_0_5*x_6_6 + 38*x_0_6*x_1_0 + 38*x_0_6*x_1_5 + 13*x_0_6*x_2_0 + 13*x_0_6*x_2_5 + 24*x_0_6*x_3_0 + 24*x_0_6*x_3_5 + 73*x_0_6*x_4_0 + 73*x_0_6*x_4_5 + 47*x_0_6*x_5_0 + 47*x_0_6*x_5_5 + 32*x_0_6*x_6_0 + 32*x_0_6*x_6_5 + 50*x_1_0*x_2_1 + 50*x_1_0*x_2_6 + 28*x_1_0*x_3_1 + 28*x_1_0*x_3_6 + 42*x_1_0*x_4_1 + 42*x_1_0*x_4_6 + 57*x_1_0*x_5_1 + 57*x_1_0*x_5_6 + 6*x_1_0*x_6_1 + 6*x_1_0*x_6_6 + 50*x_1_1*x_2_0 + 50*x_1_1*x_2_2 + 28*x_1_1*x_3_0 + 28*x_1_1*x_3_2 + 42*x_1_1*x_4_0 + 42*x_1_1*x_4_2 + 57*x_1_1*x_5_0 + 57*x_1_1*x_5_2 + 6*x_1_1*x_6_0 + 6*x_1_1*x_6_2 + 50*x_1_2*x_2_1 + 50*x_1_2*x_2_3 + 28*x_1_2*x_3_1 + 28*x_1_2*x_3_3 + 42*x_1_2*x_4_1 + 42*x_1_2*x_4_3 + 57*x_1_2*x_5_1 + 57*x_1_2*x_5_3 + 6*x_1_2*x_6_1 + 6*x_1_2*x_6_3 + 50*x_1_3*x_2_2 + 50*x_1_3*x_2_4 + 28*x_1_3*x_3_2 + 28*x_1_3*x_3_4 + 42*x_1_3*x_4_2 + 42*x_1_3*x_4_4 + 57*x_1_3*x_5_2 + 57*x_1_3*x_5_4 + 6*x_1_3*x_6_2 + 6*x_1_3*x_6_4 + 50*x_1_4*x_2_3 + 50*x_1_4*x_2_5 + 28*x_1_4*x_3_3 + 28*x_1_4*x_3_5 + 42*x_1_4*x_4_3 + 42*x_1_4*x_4_5 + 57*x_1_4*x_5_3 + 57*x_1_4*x_5_5 + 6*x_1_4*x_6_3 + 6*x_1_4*x_6_5 + 50*x_1_5*x_2_4 + 50*x_1_5*x_2_6 + 28*x_1_5*x_3_4 + 28*x_1_5*x_3_6 + 42*x_1_5*x_4_4 + 42*x_1_5*x_4_6 + 57*x_1_5*x_5_4 + 57*x_1_5*x_5_6 + 6*x_1_5*x_6_4 + 6*x_1_5*x_6_6 + 50*x_1_6*x_2_0 + 50*x_1_6*x_2_5 + 28*x_1_6*x_3_0 + 28*x_1_6*x_3_5 + 42*x_1_6*x_4_0 + 42*x_1_6*x_4_5 + 57*x_1_6*x_5_0 + 57*x_1_6*x_5_5 + 6*x_1_6*x_6_0 + 6*x_1_6*x_6_5 + 32*x_2_0*x_3_1 + 32*x_2_0*x_3_6 + 82*x_2_0*x_4_1 + 82*x_2_0*x_4_6 + 53*x_2_0*x_5_1 + 53*x_2_0*x_5_6 + 44*x_2_0*x_6_1 + 44*x_2_0*x_6_6 + 32*x_2_1*x_3_0 + 32*x_2_1*x_3_2 + 82*x_2_1*x_4_0 + 82*x_2_1*x_4_2 + 53*x_2_1*x_5_0 + 53*x_2_1*x_5_2 + 44*x_2_1*x_6_0 + 44*x_2_1*x_6_2 + 32*x_2_2*x_3_1 + 32*x_2_2*x_3_3 + 82*x_2_2*x_4_1 + 82*x_2_2*x_4_3 + 53*x_2_2*x_5_1 + 53*x_2_2*x_5_3 + 44*x_2_2*x_6_1 + 44*x_2_2*x_6_3 + 32*x_2_3*x_3_2 + 32*x_2_3*x_3_4 + 82*x_2_3*x_4_2 + 82*x_2_3*x_4_4 + 53*x_2_3*x_5_2 + 53*x_2_3*x_5_4 + 44*x_2_3*x_6_2 + 44*x_2_3*x_6_4 + 32*x_2_4*x_3_3 + 32*x_2_4*x_3_5 + 82*x_2_4*x_4_3 + 82*x_2_4*x_4_5 + 53*x_2_4*x_5_3 + 53*x_2_4*x_5_5 + 44*x_2_4*x_6_3 + 44*x_2_4*x_6_5 + 32*x_2_5*x_3_4 + 32*x_2_5*x_3_6 + 82*x_2_5*x_4_4 + 82*x_2_5*x_4_6 + 53*x_2_5*x_5_4 + 53*x_2_5*x_5_6 + 44*x_2_5*x_6_4 + 44*x_2_5*x_6_6 + 32*x_2_6*x_3_0 + 32*x_2_6*x_3_5 + 82*x_2_6*x_4_0 + 82*x_2_6*x_4_5 + 53*x_2_6*x_5_0 + 53*x_2_6*x_5_5 + 44*x_2_6*x_6_0 + 44*x_2_6*x_6_5 + 51*x_3_0*x_4_1 + 51*x_3_0*x_4_6 + 65*x_3_0*x_5_1 + 65*x_3_0*x_5_6 + 22*x_3_0*x_6_1 + 22*x_3_0*x_6_6 + 51*x_3_1*x_4_0 + 51*x_3_1*x_4_2 + 65*x_3_1*x_5_0 + 65*x_3_1*x_5_2 + 22*x_3_1*x_6_0 + 22*x_3_1*x_6_2 + 51*x_3_2*x_4_1 + 51*x_3_2*x_4_3 + 65*x_3_2*x_5_1 + 65*x_3_2*x_5_3 + 22*x_3_2*x_6_1 + 22*x_3_2*x_6_3 + 51*x_3_3*x_4_2 + 51*x_3_3*x_4_4 + 65*x_3_3*x_5_2 + 65*x_3_3*x_5_4 + 22*x_3_3*x_6_2 + 22*x_3_3*x_6_4 + 51*x_3_4*x_4_3 + 51*x_3_4*x_4_5 + 65*x_3_4*x_5_3 + 65*x_3_4*x_5_5 + 22*x_3_4*x_6_3 + 22*x_3_4*x_6_5 + 51*x_3_5*x_4_4 + 51*x_3_5*x_4_6 + 65*x_3_5*x_5_4 + 65*x_3_5*x_5_6 + 22*x_3_5*x_6_4 + 22*x_3_5*x_6_6 + 51*x_3_6*x_4_0 + 51*x_3_6*x_4_5 + 65*x_3_6*x_5_0 + 65*x_3_6*x_5_5 + 22*x_3_6*x_6_0 + 22*x_3_6*x_6_5 + 99*x_4_0*x_5_1 + 99*x_4_0*x_5_6 + 45*x_4_0*x_6_1 + 45*x_4_0*x_6_6 + 99*x_4_1*x_5_0 + 99*x_4_1*x_5_2 + 45*x_4_1*x_6_0 + 45*x_4_1*x_6_2 + 99*x_4_2*x_5_1 + 99*x_4_2*x_5_3 + 45*x_4_2*x_6_1 + 45*x_4_2*x_6_3 + 99*x_4_3*x_5_2 + 99*x_4_3*x_5_4 + 45*x_4_3*x_6_2 + 45*x_4_3*x_6_4 + 99*x_4_4*x_5_3 + 99*x_4_4*x_5_5 + 45*x_4_4*x_6_3 + 45*x_4_4*x_6_5 + 99*x_4_5*x_5_4 + 99*x_4_5*x_5_6 + 45*x_4_5*x_6_4 + 45*x_4_5*x_6_6 + 99*x_4_6*x_5_0 + 99*x_4_6*x_5_5 + 45*x_4_6*x_6_0 + 45*x_4_6*x_6_5 + 55*x_5_0*x_6_1 + 55*x_5_0*x_6_6 + 55*x_5_1*x_6_0 + 55*x_5_1*x_6_2 + 55*x_5_2*x_6_1 + 55*x_5_2*x_6_3 + 55*x_5_3*x_6_2 + 55*x_5_3*x_6_4 + 55*x_5_4*x_6_3 + 55*x_5_4*x_6_5 + 55*x_5_5*x_6_4 + 55*x_5_5*x_6_6 + 55*x_5_6*x_6_0 + 55*x_5_6*x_6_5 (49 variables, 14 constraints, 'TSP')\n"
     ]
    }
   ],
   "source": [
    "with open(\"experiment_grid_tsp.json\", \"r\") as f:\n",
    "    loaded = json.load(f)\n",
    "\n",
    "def keys_to_int(d):\n",
    "    \"\"\"Recursively convert all string keys that look like integers to int.\"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        new_dict = {}\n",
    "        for k, v in d.items():\n",
    "            # Convert numeric string keys to int\n",
    "            new_key = int(k) if isinstance(k, str) and k.isdigit() else k\n",
    "            new_dict[new_key] = keys_to_int(v)\n",
    "        return new_dict\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "exp_grid_loaded = [keys_to_int(entry) for entry in loaded]\n",
    "\n",
    "#print(exp_grid_loaded[50]['G'])  # should match your original structure\n",
    "\n",
    "loaded = Tsp(exp_grid_loaded[50]['G'])\n",
    "print(loaded.to_quadratic_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7f7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "num_params = 8999          # number of parameters in your ansatz\n",
    "seeds = list(range(10))       # 10 seeds: 0..9\n",
    "save_dir = \"theta_inits\"      # folder to save all\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for seed in seeds:\n",
    "    g = torch.Generator(device=\"cpu\").manual_seed(seed)\n",
    "    # Uniform angle in [-π, π]\n",
    "    theta_init = (2 * torch.pi) * torch.rand(num_params, generator=g) - torch.pi\n",
    "\n",
    "    # Save tensor\n",
    "    torch.save(theta_init, f\"{save_dir}/theta_init_s{seed}_extra.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
